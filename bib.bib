@inbook{boas2013overview,
  title={Overview of virtual reality technologies},
  author={Boas, YAGV},
  booktitle={Interactive Multimedia Conference},
  volume={2013},
  year={2013}
}

@article{Kitchenham2013,
title = {A systematic review of systematic review process research in software engineering},
journal = {Information and Software Technology},
volume = {55},
number = {12},
pages = {2049-2075},
year = {2013},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2013.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S0950584913001560},
author = {Barbara Kitchenham and Pearl Brereton},
keywords = {Systematic review, Systematic literature review, Systematic review methodology, Mapping study},
abstract = {Context
Many researchers adopting systematic reviews (SRs) have also published papers discussing problems with the SR methodology and suggestions for improving it. Since guidelines for SRs in software engineering (SE) were last updated in 2007, we believe it is time to investigate whether the guidelines need to be amended in the light of recent research.
Objective
To identify, evaluate and synthesize research published by software engineering researchers concerning their experiences of performing SRs and their proposals for improving the SR process.
Method
We undertook a systematic review of papers reporting experiences of undertaking SRs and/or discussing techniques that could be used to improve the SR process. Studies were classified with respect to the stage in the SR process they addressed, whether they related to education or problems faced by novices and whether they proposed the use of textual analysis tools.
Results
We identified 68 papers reporting 63 unique studies published in SE conferences and journals between 2005 and mid-2012. The most common criticisms of SRs were that they take a long time, that SE digital libraries are not appropriate for broad literature searches and that assessing the quality of empirical studies of different types is difficult.
Conclusion
We recommend removing advice to use structured questions to construct search strings and including advice to use a quasi-gold standard based on a limited manual search to assist the construction of search stings and evaluation of the search process. Textual analysis tools are likely to be useful for inclusion/exclusion decisions and search string construction but require more stringent evaluation. SE researchers would benefit from tools to manage the SR process but existing tools need independent validation. Quality assessment of studies using a variety of empirical methods remains a major problem.}
}

@inbook{Dahl2025splash,
author = {Dahl, Joshua and Harris Jr., Frederick C.},
title = {An Argument for the Practicality of Entity Component Systems as the Primary Data Structure for an Interpreter or Compiler},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the 2025 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
keywords = {Configuration, Data Specification, Programming Language},
location = {Singapore},
series = {Onward! '25},
}

@article{dahl2023umuvr,
  title={uMuVR: A Multiuser Virtual Reality and Body Presence Framework for Unity.},
  author={Dahl, Joshua and Marsh, Erik and Lewis, Christopher and Harris Jr, Frederick C},
  journal={International Journal for Computers & Their Applications},
  volume={30},
  number={1},
  year={2023}
}

@article{dahl2023muvr,
  title={MuVR: A multiuser virtual reality framework for Unity},
  author={Dahl, Joshua and Marsh, Erik and Lewis, Christopher and Harris, Frederick},
  journal={EPiC Series in Computing},
  doir={https://doi.org/10.29007/jdlg},
  url={https://easychair.org/publications/paper/bfGR},
  volume={88},
  year={2023},
}

@article{marsh2023,
author="Marsh, Erik
and Dahl, Joshua
and Kamran Pishhesari, Alireza
and Sattarvand, Javad
and Harris, Frederick C.",
editor="Latifi, Shahram",
title="A Virtual Reality Mining Training Simulator for Proximity Detection",
booktitle="ITNG 2023 20th International Conference on Information Technology-New Generations",
year="2023",
publisher="Springer International Publishing",
address="Cham",
pages="387--393",
abstract="Many applications in industrial mining rely on large manually operated trucks to transport materials around the mine. These trucks are often enormous, with very limited visibility for the driver. The combination of limited visibility and a truck with a substantial amount of weight is a recipe for accidents resulting in severe property destruction or even loss of human life. To solve these issues, we implement a simulation of a LIDAR-based proximity collision detection system to notify drivers of an imminent collision with something (or someone) outside of their field of view. We have developed a virtual reality training simulation to help train miners how to use this new system. Our simulation focuses on two main participant types: truck drivers and ground workers. This separation allows both parties to gain experience operating around the other in a low-risk virtual environment. Our final result aggregated useful features from a variety of past works and enhanced them with more immersive input and output devices.",
isbn="978-3-031-28332-1",
doi="https://doi.org/10.1007/978-3-031-28332-1_44"
}

@article{contaldi2025,
author="Contaldi, Quinn
and Dahl, Joshua
and Charyyev, Batyr
and Harris, Frederick C.",
editor="Latifi, Shahram",
title="Analyzing ``Existential Dread'' on the Internet in Response to Elmo",
booktitle="The 22nd International Conference on Information Technology-New Generations (ITNG 2025)",
year="2025",
publisher="Springer Nature Switzerland",
address="Cham",
pages="167--177",
isbn="978-3-031-89063-5",
doi="https://doi.org/10.1007/978-3-031-89063-5_15"
}


@software{ctre,
    author = {Dusíková, Hana},
    license = {Apache-2.0},
    title = {{Compile time regular expressions}},
    url = {https://github.com/hanickadot/compile-time-regular-expressions},
    urldate = {2024-12-13}, 
}

@software{cfront,
    author = {Stroustrup, Bjarne},
    title = {{cfront}},
    url = {https://www.softwarepreservation.org/projects/c_plus_plus/index.html#cfront},
    urldate = {2024-12-13}, 
}

@software{cppfront,
    author = {Sutter, Herb},
    license = {Apache-2.0 WITH LLVM-exception},
    title = {{cppfront}},
    url = {https://github.com/hsutter/cppfront},
    urldate = {2024-12-13}, 
}

@software{nim,
    author = {Rumpf, Andreas},
    license = {MIT},
    title = {{Nim}},
    url = {https://github.com/nim-lang/Nim},
    urldate = {2024-12-13}, 
}

@software{ufcs,
  title={Unified call syntax},
  author={Sutter, Herb},
  year={2014},
  publisher={N40xx},
  URL = {https://isocpp.org/files/papers/N4165.pdf},
  urldate = {2024-12-13}, 
}

@software{vscode,
  author = {{Microsoft}},
  title = {Visual Studio Code},
  year = {2025},
  url = {https://code.visualstudio.com/},
  urldate = {2025-5-15}, 
}

@software{gcc,
  author = {{Free Software Foundation}},
  title = {GNU Compiler Collection (GCC)},
  year = {2025},
  url = {https://gcc.gnu.org/},
  urldate = {2025-5-15}, 
}

@software{dahlufcs,
  author       = {Joshua Dahl},
  title        = {Uniform Function Call Syntax for C},
  year         = {2024},
  url          = {https://github.com/joshuadahlunr/UFCS},
  urldate = {2025-05-19}
}

@article{buse2011,
author = {Buse, Raymond P.L. and Sadowski, Caitlin and Weimer, Westley},
title = {Benefits and barriers of user evaluation in software engineering research},
year = {2011},
issue_date = {October 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/2076021.2048117},
doi = {10.1145/2076021.2048117},
abstract = {In this paper, we identify trends about, benefits from, and barriers to performing user evaluations in software engineering research. From a corpus of over 3,000 papers spanning ten years, we report on various subtypes of user evaluations (e.g., coding tasks vs. questionnaires) and relate user evaluations to paper topics (e.g., debugging vs. technology transfer). We identify the external measures of impact, such as best paper awards and citation counts, that are correlated with the presence of user evaluations. We complement this with a survey of over 100 researchers from over 40 different universities and labs in which we identify a set of perceived barriers to performing user evaluations.},
journal = {SIGPLAN Not.},
month = oct,
pages = {643–656},
numpages = {14},
keywords = {user evaluation, software engineering, human study}
}

@article{chamberlain2017,
author = {Chamberlain, Roger D.},
title = {Assessing user preferences in programming language design},
year = {2017},
isbn = {9781450355308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3133850.3133851},
doi = {10.1145/3133850.3133851},
abstract = {The design of new programming languages has primarily been guided by the preferences of a few (the authors of the language), rather than systematic study of the various options available. This is in part due to the fact that user studies to effectively test usability or understandability hypotheses are cumbersome and expensive. An interesting question is whether crowdsourcing techniques can be leveraged to improve this situation.  We explore this idea using a specific example. While the streaming data paradigm is a popular one for expressing parallelism within applications, there has been little consensus on the methods used to express streaming topologies. Here, we explore the use of Mechanical Turk to recruit self-described programmers as a community to assess user preferences and code readability for two techniques currently in use for the expression of streaming application topology.  The positive results of this study point to the idea that crowdsourcing techniques can be an effective technique that can inexpensively assist language developers in making good design choices.},
booktitle = {Proceedings of the 2017 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {18–29},
numpages = {12},
keywords = {Crowdsourcing, streaming language design, user studies},
location = {Vancouver, BC, Canada},
series = {Onward! 2017}
}

@article{stefik2013,
author = {Stefik, Andreas and Siebert, Susanna},
title = {An Empirical Investigation into Programming Language Syntax},
year = {2013},
issue_date = {November 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
url = {https://doi.org/10.1145/2534973},
doi = {10.1145/2534973},
abstract = {Recent studies in the literature have shown that syntax remains a significant barrier to novice computer science students in the field. While this syntax barrier is known to exist, whether and how it varies across programming languages has not been carefully investigated. For this article, we conducted four empirical studies on programming language syntax as part of a larger analysis into the, so called, programming language wars. We first present two surveys conducted with students on the intuitiveness of syntax, which we used to garner formative clues on what words and symbols might be easy for novices to understand. We followed up with two studies on the accuracy rates of novices using a total of six programming languages: Ruby, Java, Perl, Python, Randomo, and Quorum. Randomo was designed by randomly choosing some keywords from the ASCII table (a metaphorical placebo). To our surprise, we found that languages using a more traditional C-style syntax (both Perl and Java) did not afford accuracy rates significantly higher than a language with randomly generated keywords, but that languages which deviate (Quorum, Python, and Ruby) did. These results, including the specifics of syntax that are particularly problematic for novices, may help teachers of introductory programming courses in choosing appropriate first languages and in helping students to overcome the challenges they face with syntax.},
journal = {ACM Trans. Comput. Educ.},
month = nov,
articleno = {19},
numpages = {40},
keywords = {Novice Programmers, Programming Languages, Syntax}
}

@article{stefik2011,
title = {An empirical investigation into the design of auditory cues to enhance computer program comprehension},
journal = {International Journal of Human-Computer Studies},
volume = {69},
number = {12},
pages = {820-838},
year = {2011},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2011.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S1071581911000814},
author = {Andreas Stefik and Christopher Hundhausen and Robert Patterson},
keywords = {Auditory programming, Programming, Debugging, Program comprehension},
abstract = {Decades of research have led to notable improvements in the representations used to aid human comprehension of computer programs. Much of this research has focused on visual representations, which leaves open the question of how best to design auditory representations of computer programs. While this question has particular relevance for visually impaired programmers, sighted programmers might also benefit from enhanced auditory representations of their programs. In order to investigate this question empirically, first, we introduce artifact encoding, a novel approach to rigorously measuring the comprehensibility of auditory representations of computer programs. Using this approach as a foundation, we present an experimental study that compared the comprehensibility of two alternative auditory program representations: one with lexical scoping cues that convey the nesting level of program statements, and another without such scoping cues. The results of our first experiment validate both artifact encoding and the scoping cues we used. To see whether auditory cues validated through our paradigm can aid program comprehension in a realistic task scenario, we experimentally compared programmers' ability to debug programs using three alternative environments: (1) an auditory execution environment with our empirically derived auditory cues; (2) an auditory execution environment with the current state-of-the-art auditory cues generated by a screen reader running on top of Microsoft Visual Studio; and (3) a visual version of the execution environment. The results of our second experiment showed that our comprehensible auditory cues are significantly better than the state-of-the-art, affording human performance approaching the effectiveness of visual representations within the statistical margin of error. This research contributes a novel methodology and foundational empirical data that can guide the design of effective auditory representations of computer programs.}
}
 
@software{mizu,
author = {Joshua Dahl},
doi = {10.5281/zenodo.15578022},
license = {["mit"]},
month = jun,
title = {Mizu Source Code},
url = {https://github.com/joshuadahlunr/MizuVM/tree/paper},
urldate = {2025-07-08},
version = {paper},
year = {2025}
}

@software{constexpr,
  author       = {{cppreference}},
  title        = {constexpr specifier - cppreference.com},
  year         = {2025},
  url          = {https://en.cppreference.com/w/cpp/language/constexpr},
  urldate = {2025-07-08},
}

@software{comptime,
  author       = {{Zig Software Foundation}},
  title        = {Zig Documentation: {comptime}},
  year         = {2025},
  url          = {https://ziglang.org/documentation/master/#comptime},
  urldate = {2025-07-08},
}

@software{libffi,
  author       = {{libffi Contributors}},
  title        = {libffi - Portable Foreign Function Interface Library},
  year         = {2025},
  url          = {https://github.com/libffi/libffi},
  urldate = {2025-07-08},
}

@software{wasisdk,
  author       = {{WebAssembly Community Group}},
  title        = {WASI‑SDK – WebAssembly System Interface SDK},
  year         = {2025},
  url          = {https://github.com/WebAssembly/wasi-sdk},
  urldate = {2025-07-08},
}

@software{wasm3mcu,
  author       = {{wasm3 contributors}},
  title        = {Wasm3 Performance — “Wasm3 on MCUs” Section},
  year         = {2025},
  url          = {https://github.com/wasm3/wasm3/blob/main/docs/Performance.md#wasm3-on-mcus},
  urldate = {2025-07-08},
}

@software{wasm3,
  author       = {{wasm3 contributors}},
  title        = {wasm3 – High‑performance WebAssembly Runtime},
  year         = {2025},
  url          = {https://github.com/wasm3/wasm3},
  urldate = {2025-07-08},
}

@software{nodejs,
  author       = {{OpenJS Foundation}},
  title        = {Node.js – JavaScript Runtime},
  year         = {2025},
  url          = {https://nodejs.org/en},
  urldate = {2025-07-08},
}

@software{luajit,
  author       = {Mike Pall and {LuaJIT Project}},
  title        = {LuaJIT – Just‑in‑Time Compiler for Lua},
  year         = {2025},
  url          = {https://luajit.org/},
  urldate = {2025-07-08},
}

@software{dotnet,
  author       = {Microsoft},
  title        = {.NET (dotnet.microsoft.com) – Free · Cross‑Platform · Open Source Developer Platform},
  year         = {2025},
  url          = {https://dotnet.microsoft.com/},
  urldate = {2025-07-08},
}

@software{benchmark,
  author       = {Joshua Dahl},
  title        = {MizuBenchmark – Cross-Language Benchmarking Suite},
  year         = {2025},
  url          = {https://github.com/doir-lang/MizuBenchmark},
  urldate = {2025-07-08},
}

@inbook{llvm,
  author={Lattner, C. and Adve, V.},
  booktitle={International Symposium on Code Generation and Optimization, 2004. CGO 2004.}, 
  title={LLVM: a compilation framework for lifelong program analysis & transformation}, 
  year={2004},
  volume={},
  number={},
  pages={75-86},
  keywords={Information analysis;Program processors;Performance analysis;High level languages;Virtual machining;Runtime;Arithmetic;Application software;Software safety;Algorithm design and analysis},
  doi={10.1109/CGO.2004.1281665}}

@ARTICLE{Cui2023,
  author={Cui, Enfang and Li, Tianzheng and Wei, Qian},
  journal={IEEE Access}, 
  title={RISC-V Instruction Set Architecture Extensions: A Survey}, 
  year={2023},
  volume={11},
  number={},
  pages={24696-24711},
  keywords={Instruction sets;Microprocessors;Computer architecture;Task analysis;Graphics processing units;Cloud computing;Artificial intelligence;RISC-V;instruction set architecture;extensions;survey},
  doi={10.1109/ACCESS.2023.3246491}}

@inbook{Anderson2021,
  author    = { {T}odd {A}nderson and {T}im {M}attson },
  title     = { {M}ultithreaded parallel {P}ython through {O}pen{M}{P} support in {N}umba },
  booktitle = { {P}roceedings of the 20th {P}ython in {S}cience {C}onference },
  pages     = { 140 - 147 },
  year      = { 2021 },
  editor    = { {M}eghann {A}garwal and {C}hris {C}alloway and {D}illon {N}iederhut and {D}avid {S}hupe },
  doi       = { 10.25080/majora-1b6fd038-012 }
}

@webpage{wihuri2023,
  title={A case study on parallelism and multithreading in a meteorological JavaScript web application},
  author={Wihuri, Alvar},
  year={2023},
  url = {https://aaltodoc.aalto.fi/items/71feb1c5-fa75-4af9-a5d0-6afaf34659d8},
  urldate      = {2025-07-08},
}

@ARTICLE{ieee754,
  author={IEEE},
  journal={IEEE Std 754-2019 (Revision of IEEE 754-2008)}, 
  title={IEEE Standard for Floating-Point Arithmetic}, 
  year={2019},
  volume={},
  number={},
  pages={1-84},
  keywords={IEEE Standards;Floating-point arithmetic;arithmetic;binary;computer;decimal;exponent;floating-point;format;IEEE 754;interchange;NaN;number;rounding;significand;subnormal.},
  doi={10.1109/IEEESTD.2019.8766229}}

@inbook{numba,
author = {Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
title = {Numba: a LLVM-based Python JIT compiler},
year = {2015},
isbn = {9781450340052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2833157.2833162},
doi = {10.1145/2833157.2833162},
abstract = {Dynamic, interpreted languages, like Python, are attractive for domain-experts and scientists experimenting with new ideas. However, the performance of the interpreter is often a barrier when scaling to larger data sets. This paper presents a just-in-time compiler for Python that focuses in scientific and array-oriented computing. Starting with the simple syntax of Python, Numba compiles a subset of the language into efficient machine code that is comparable in performance to a traditional compiled language. In addition, we share our experience in building a JIT compiler using LLVM[1].},
booktitle = {Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC},
articleno = {7},
numpages = {6},
keywords = {LLVM, Python, compiler},
location = {Austin, Texas},
series = {LLVM '15}
}

@article{lua,
author = {Ierusalimschy, Roberto and de Figueiredo, Luiz Henrique and Filho, Waldemar Celes},
title = {Lua—An Extensible Extension Language},
journal = {Software: Practice and Experience},
volume = {26},
number = {6},
pages = {635-652},
keywords = {extension languages, end-user programming, programming languages},
doi = {10.1002/(SICI)1097-024X(199606)26:6<635::AID-SPE26>3.0.CO;2-P},
year = {1996}
}

@inbook{emscripten,
author = {Zakai, Alon},
title = {Emscripten: an LLVM-to-JavaScript compiler},
year = {2011},
isbn = {9781450309424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/2048147.2048224},
booktitle = {Proceedings of the ACM International Conference Companion on Object Oriented Programming Systems Languages and Applications Companion},
pages = {301–312},
numpages = {12},
keywords = {llvm, javascript, decompiler},
location = {Portland, Oregon, USA},
series = {OOPSLA '11}
}

@inbook{Berndl2005,
  author={Berndl, M. and Vitale, B. and Zaleski, M. and Brown, A.D.},
  booktitle={International Symposium on Code Generation and Optimization}, 
  title={Context threading: a flexible and efficient dispatch technique for virtual machine interpreters}, 
  year={2005},
  volume={},
  number={},
  pages={15-26},
  keywords={Virtual machining;Hardware;Context-aware services;Java;Algorithms;Counting circuits;Computer languages;Pipelines;Hazards;Debugging},
  doi={10.1109/CGO.2005.14}}

@webpage{curley1993,
  title={Life in the FastForth lane},
  author={Curley, Charles},
  journal={Forth Dimensions},
  volume={14},
  number={4},
  pages={6--12},
  year={1993},
  url={https://www.forth.org/fd/curley2.html},
  urldate={2025-8-7}

}

@inbook{10.1145/964001.964011,
author = {Ford, Bryan},
title = {Parsing expression grammars: a recognition-based syntactic foundation},
year = {2004},
isbn = {158113729X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/964001.964011},
doi = {10.1145/964001.964011},
abstract = {For decades we have been using Chomsky's generative system of grammars, particularly context-free grammars (CFGs) and regular expressions (REs), to express the syntax of programming languages and protocols. The power of generative grammars to express ambiguity is crucial to their original purpose of modelling natural languages, but this very power makes it unnecessarily difficult both to express and to parse machine-oriented languages using CFGs. Parsing Expression Grammars (PEGs) provide an alternative, recognition-based formal foundation for describing machine-oriented syntax, which solves the ambiguity problem by not introducing ambiguity in the first place. Where CFGs express nondeterministic choice between alternatives, PEGs instead use prioritized choice. PEGs address frequently felt expressiveness limitations of CFGs and REs, simplifying syntax definitions and making it unnecessary to separate their lexical and hierarchical components. A linear-time parser can be built for any PEG, avoiding both the complexity and fickleness of LR parsers and the inefficiency of generalized CFG parsing. While PEGs provide a rich set of operators for constructing grammars, they are reducible to two minimal recognition schemas developed around 1970, TS/TDPL and gTS/GTDPL, which are here proven equivalent in effective recognition power.},
booktitle = {Proceedings of the 31st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {111–122},
numpages = {12},
keywords = {unified grammars, syntactic predicates, scannerless parsing, regular expressions, parsing expression grammars, packrat parsing, lexical analysis, context-free grammars, TDPL, GTDPL, BNF},
location = {Venice, Italy},
series = {POPL '04}
}

@article{ford2004,
author = {Ford, Bryan},
title = {Parsing expression grammars: a recognition-based syntactic foundation},
year = {2004},
issue_date = {January 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0362-1340},
url = {https://doi.org/10.1145/982962.964011},
doi = {10.1145/982962.964011},
abstract = {For decades we have been using Chomsky's generative system of grammars, particularly context-free grammars (CFGs) and regular expressions (REs), to express the syntax of programming languages and protocols. The power of generative grammars to express ambiguity is crucial to their original purpose of modelling natural languages, but this very power makes it unnecessarily difficult both to express and to parse machine-oriented languages using CFGs. Parsing Expression Grammars (PEGs) provide an alternative, recognition-based formal foundation for describing machine-oriented syntax, which solves the ambiguity problem by not introducing ambiguity in the first place. Where CFGs express nondeterministic choice between alternatives, PEGs instead use prioritized choice. PEGs address frequently felt expressiveness limitations of CFGs and REs, simplifying syntax definitions and making it unnecessary to separate their lexical and hierarchical components. A linear-time parser can be built for any PEG, avoiding both the complexity and fickleness of LR parsers and the inefficiency of generalized CFG parsing. While PEGs provide a rich set of operators for constructing grammars, they are reducible to two minimal recognition schemas developed around 1970, TS/TDPL and gTS/GTDPL, which are here proven equivalent in effective recognition power.},
journal = {SIGPLAN Not.},
month = jan,
pages = {111–122},
numpages = {12},
keywords = {unified grammars, syntactic predicates, scannerless parsing, regular expressions, parsing expression grammars, packrat parsing, lexical analysis, context-free grammars, TDPL, GTDPL, BNF}
}

@webpage{carruth2023,
  author       = {Chandler Carruth},
  title        = {Modernizing Compiler Design for Carbon’s Toolchain (slides)},
  year         = {2023},
  month        = {May},
  url          = {https://chandlerc.blog/slides/2023-cppnow-compiler},
  urldate      = {2025-04-15},
}

@webpage{carruth2023youtube,
  author       = {Chandler Carruth},
  title        = {Modernizing Compiler Design for Carbon Toolchain (lecture)},
  year         = {2023},
  month        = {May},
  url          = {https://www.youtube.com/watch?v=ZI198eFghJk},
  urldate      = {2025-04-15},
}

@software{carbon-lang,
  author       = {{Carbon Developers}},
  title        = {Carbon Language: An experimental successor to C++},
  year         = {2025},
  url          = {https://github.com/carbon-language/carbon-lang},
  urldate      = {2025-04-15},
  license      = {Apache License 2.0 with LLVM Exception},
}

@software{unity-dots,
  author       = {{Unity Technologies}},
  title        = {Unity’s Data-Oriented Technology Stack (DOTS)},
  year         = {2023},
  url          = {https://unity.com/dots},
  urldate      = {2025-04-15},
}

@software{epic-mass,
  author       = {{Epic Games}},
  title        = {Large Numbers of Entities with Mass in Unreal Engine 5},
  year         = {2022},
  url          = {https://dev.epicgames.com/community/learning/talks-and-demos/37Oz/large-numbers-of-entities-with-mass-in-unreal-engine-5},
  urldate      = {2025-04-15},
  eventdate    = {2022-04-05},
  location     = {Online},
}

@software{bevy,
  author       = {Bevy-Contributors},
  year = {2025},
  title        = {Bevy Engine},
  version      = {0.10.0},
  urldate      = {2025-04-15},
  abstract     = {A refreshingly simple data-driven game engine built in Rust},
  url = {https://github.com/bevyengine/bevy/releases/tag/v0.10.0},
  langid       = {english},
}

@webpage{json,
  author       = {Douglas Crockford},
  title        = {Introducing JSON},
  year         = {2025},
  url          = {https://www.json.org/json-en.html},
  urldate      = {2025-04-15},
}

@webpage{igoro-cache,
  author       = {Igor Ostrovsky},
  title        = {Gallery of Processor Cache Effects},
  year         = {2010},
  url          = {https://igoro.com/archive/gallery-of-processor-cache-effects/},
  urldate      = {2025-04-15},
}

@article{pod-serialization,
	author = {{Gaede, Frank} and {Hegner, Benedikt} and {Stewart, Graeme A.}},
	title = {PODIO: recent developments in the Plain Old Data EDM toolkit},
	DOI= "10.1051/epjconf/202024505024",
	url= "https://doi.org/10.1051/epjconf/202024505024",
	journal = {EPJ Web Conf.},
	year = 2020,
	volume = 245,
	pages = "05024",
}


@webpage{tuni2019,
  author       = {Toni Härkönen},
  title        = {Advantages and Implementation of Entity-Component-Systems},
  year         = {2019},
  month        = {May},
  url          = {https://trepo.tuni.fi/handle/123456789/27593},
  urldate      = {2025-04-15},
  note = {Bachelor's thesis. Tampere University, Tampere, Finland.}
}

@webpage{std_sort,
  author       = {cppreference},
  title        = {std::sort - cppreference.com},
  year         = {2025},
  url          = {https://en.cppreference.com/w/cpp/algorithm/sort},
  urldate      = {2025-04-15},
}

@article{basili1997,
  author    = {V. R. Basili and G. Caldiera and H. D. Rombach},
  title     = {The Goal Question Metric Approach},
  journal   = {Software Engineering Journal},
  volume    = {27},
  number    = {8},
  pages     = {983--1001},
  year      = {1997},
  doi       = {10.1002/(SICI)1097-024X(199708)27:8<983::AID-SPE117>3.0.CO;2-\#},
  url       = {https://onlinelibrary.wiley.com/doi/10.1002/%28SICI%291097-024X%28199708%2927%3A8%3C983%3A%3AAID-SPE117%3E3.0.CO%3B2-%23},
}

@webpage{guinness_fastest_court_reporter,
  title        = {Fastest realtime court reporter (stenotype writing)},
  author       = {{Guinness World Records}},
  year         = {2004},
  url          = {https://www.guinnessworldrecords.com/world-records/fastest-realtime-court-reporter-%28stenotype-writing%29},
  urldate      = {2025-04-15},
}

@webpage{carlton2011,
  author       = {Brian Carlton},
  title        = {Answer to: Most difficult subject/theory in Computer Science?},
  year         = {2011},
  month        = {January},
  url          = {https://softwareengineering.stackexchange.com/a/41674},
  urldate      = {2025-04-15},
  organization = {Software Engineering Stack Exchange},
}

@inbook{Mrena2022,
  author={Mrena, Michal and Varga, Michal and Kvassay, Miroslav},
  booktitle={2022 IEEE 16th International Scientific Conference on Informatics (Informatics)}, 
  title={Experimental Comparison of Array-based and Linked-based List Implementations}, 
  year={2022},
  volume={},
  number={},
  pages={231-238},
  doi={10.1109/Informatics57926.2022.10083495}
}

@webpage{leitner2016,
  author       = {Martin Leitner-Ankerl},
  title        = {Very Fast HashMap in C++: Benchmark Results (Part 3)},
  year         = {2016},
  month        = {September},
  url          = {https://martin.ankerl.com/2016/09/21/very-fast-hashmap-in-c-part-3/},
  urldate      = {2025-04-15},
  organization = {martin.ankerl.com},
}

@inbook{Herlihy2008,
    author="Herlihy, Maurice
    and Shavit, Nir
    and Tzafrir, Moran",
    editor="Taubenfeld, Gadi",
    title="Hopscotch Hashing",
    booktitle="Distributed Computing",
    year="2008",
    publisher="Springer Berlin Heidelberg",
    address="Berlin, Heidelberg",
    pages="350--364",
    isbn="978-3-540-87779-0",
    doi="10.1007/978-3-540-87779-0_24"
}

@webpage{fnv_hash,
  author       = {Landon Curt Noll},
  title        = {FNV Hash Function},
  year         = {2009},
  url          = {http://www.isthe.com/chongo/tech/comp/fnv/},
  urldate      = {2025-04-15},
}

@book{nystrom2021,
  title={Crafting interpreters},
  author={Nystrom, Robert},
  year={2021},
  publisher={Genever Benning},
  isbn={978-0990582939}
}

@webpage{colson2020,
  author       = {David Colson},
  title        = {How to Make a Simple Entity-Component-System in C++},
  year         = {2020},
  month        = {February},
  url          = {https://www.david-colson.com/2020/02/09/making-a-simple-ecs.html},
  urldate      = {2025-04-15},
}

@software{nanobench,
  author       = {Martin Leitner-Ankerl},
  title        = {ankerl::nanobench: Simple, Fast, Accurate Single-Header Microbenchmarking for C++},
  year         = {2023},
  url          = {https://nanobench.ankerl.com/},
  urldate      = {2025-04-15},
  license      = {MIT License}
}

@software{cpython,
  author       = {{Python Software Foundation}},
  title        = {CPython: The Python Programming Language},
  year         = {2025},
  url          = {https://github.com/python/cpython},
  urldate      = {2025-04-17},
}

@book{lindholm2013,
  title={The Java Virtual Machine Specification, Java SE 7 Edition},
  author={Lindholm, T. and Yellin, F. and Bracha, G. and Buckley, A.},
  isbn={9780133260465},
  series={Java Series},
  url={https://books.google.com/books?id=95HzjxTELRkC},
  year={2013},
  publisher={Pearson Education},
}

@software{nystrom2025tests,
  author       = {Bob Nystrom},
  title        = {Benchmark Test from the Crafting Interpreters Repository},
  year         = {2025},
  url = {https://github.com/munificent/craftinginterpreters/blob/master/test/},
  urldate = {2025-04-24},
}

@software{cloutier2023,
  author       = {Tyler Cloutier},
  title        = {Databases are the endgame for data-oriented design},
  year         = {2023},
  month        = dec,
  url          = {https://spacetimedb.com/blog/databases-and-data-oriented-design},
  urldate = {2025-04-24},
}

@software{flecs,
  author       = {Sander Mertens},
  title        = {flecs: A fast and lightweight Entity Component System (ECS) for C/C++},
  year         = {2025},
  month        = mar,
  url = {https://github.com/SanderMertens/flecs},
  urldate = {2025-04-24},
}

@software{dahl2025serialize,
  author       = {Joshua Dahl},
  title        = {{serialize.cpp} - Part of the {DOIR} Project},
  year         = {2025},
  url = {https://github.com/data-oriented-ir/DOIR/blob/ECS4Compilers/src/Lox/serialize.cpp},
  urldate = {2025-04-24},
}

@software{dahl2025benchmarklox,
  author       = {Joshua Dahl},
  title        = {{benchmark_lox.cpp.bench} - Benchmark Test from the {DOIR} Project},
  year         = {2025},
  url = {https://github.com/data-oriented-ir/DOIR/blob/benchmark/tests/benchmark_lox.cpp.bench},
  urldate = {2025-04-24},
}

@software{dahl2025startupcost,
  author       = {Joshua Dahl},
  title        = {Platform Executable Startup Cost},
  year         = {2025},
  url          = {https://gist.github.com/joshuadahlunr/fa99761edcfbdaaf4aec8ef93396ef42},
  urldate = {2025-06-27},
}

@software{asteroids_recharged,
  title        = {Asteroids: Recharged},
  author       = {{Atari}},
  year         = 2021,
  url          = {https://atari.com/products/asteroids-recharged},
  urldate = {2025-06-22},
}

@software{rustMultiLevel,
  author       = {{The Rustc Dev Guide Team}},
  title        = {Part 3: Middle-End and Back-End},
  year         = {2024},
  url          = {https://rustc-dev-guide.rust-lang.org/part-3-intro.html},
  urldate         = {2025-07-16},
}

@inbook{stefik2017,
author = {Stefik, Andreas and Ladner, Richard},
title = {The Quorum Programming Language (Abstract Only)},
year = {2017},
isbn = {9781450346986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3017680.3022377},
doi = {10.1145/3017680.3022377},
abstract = {Quorum is a relatively new programming language that was originally designed for students with disabilities. In recent years, as its adoption has increased worldwide in K-12 (largely in middle/high school) and at universities, it has expanded to be a powerful, commercial-grade, programming language that includes support for 3D gaming, music, and other fun and creative activities. While new features are designed for all, they maintain compatibility for people with disabilities, including a novel way for individuals who are blind to create 3D games. Finally, Quorum is the first language to use human-factors evidence from both field data and randomized controlled trials in its design. This approach provides the broader research community an organized way to influence the design of the language over time according to evidence based practices. We call this approach evidence-oriented programming. A laptop would help participants follow along with the session and handouts will be provided. Quorum can be found at https://www.quorumlanguage.com/.},
booktitle = {Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education},
pages = {641},
numpages = {1},
keywords = {accessibility, computer games, evidence-oriented programming, programming languages},
location = {Seattle, Washington, USA},
series = {SIGCSE '17}
}

@software{verse,
  author       = {{Epic Games}},
  title        = {{Verse Language Reference}},
  year         = {2025},
  url = {https://dev.epicgames.com/documentation/en-us/fortnite/verse-language-reference},
  urldate         = {2025-07-16}
}

@article{Stanier2013,
author = {Stanier, James and Watson, Des},
title = {Intermediate representations in imperative compilers: A survey},
year = {2013},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2480741.2480743},
doi = {10.1145/2480741.2480743},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {26},
numpages = {27},
keywords = {Compilers, intermediate representations, optimization}
}

@book{barabasi2016,
  author    = {Albert-László Barabási and Márton Pósfai},
  title     = {Network Science},
  publisher = {Cambridge University Press},
  address   = {Cambridge},
  year      = {2016},
  isbn      = {9781107076266},
  url       = {http://barabasi.com/networksciencebook/},
}

@TechReport{johnson2004,
  author = {Johnson, Neil E.},
  title = {{Code size optimization for embedded processors}},
  year = 2004,
  month = nov,
  url = {https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-607.pdf},
  institution = {University of Cambridge, Computer Laboratory},
  doi = {10.48456/tr-607},
  number = {UCAM-CL-TR-607},
  note = {Technical Report Number: UCAM-CL-TR-607, University of Cambridge, Computer Laboratory, Cambridge, United Kingdom}
}

@book{dragonbook,
  author    = {Alfred V. Aho and Monica S. Lam and Ravi Sethi and Jeffrey D. Ullman},
  title     = {Compilers: Principles, Techniques, and Tools (2nd Edition)},
  edition   = {2nd},
  year      = {2006},
  publisher = {Addison-Wesley},
  address   = {Boston, MA},
  isbn = {9780321486813},
}

@book{cooper2022,
  author    = {Keith D. Cooper and Linda Torczon},
  title     = {Engineering a Compiler},
  edition   = {3rd},
  publisher = {Morgan Kaufmann},
  year      = {2022},
  isbn      = {9780128154120},
  pages     = {848},
  address   = {San Francisco, CA},
}

@article{fraser1991,
author = {Fraser, Christopher W.},
title = {A retargetable compiler for ANSI C},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/122616.122621},
doi = {10.1145/122616.122621},
abstract = {lcc is a new retargetable compiler for ANSI C. Versions for the VAX, Motorola 68020, SPARC, and MIPS are in production use at Princeton University and at AT&T Bell Laboratories. With a few exceptions, little about lcc is unusual --- it integrates several well engineered, existing techniques --- but it is smaller and faster than most other C compilers, and it generates code of comparable quality, lcc's target-independent front end performs a few simple, but effective, optimizations that contribute to good code; examples include simulating register declarations and partitioning switch statement cases into dense tables. It also implements target-independent function tracing and expression-level profiling.},
journal = {SIGPLAN Not.},
month = oct,
pages = {29–43},
numpages = {15}
}

@book{fraser1995,
author = {Fraser, Christopher W. and Hanson, David R.},
title = {A  Retargetable C Compiler: Design and Implementation},
year = {1995},
isbn = {0805316701},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
address = {USA},
abstract = {From the Publisher:This new text examines the design and implementation of Icc, a production-quality, retargetable compiler, designed at AT&T Bell Laboratories and Princeton University for the ANSI C programming language. The authors' innovative approach - a "literate program" that intermingles the text with the source code - gives a detailed tour of the code that explains the implementation and design decisions reflected in the software. And while most books describe toy compilers or focus on isolated pieces of code, the authors have made available the entire source code for a real compiler. Structured as a self-study guide that describes the real-world tradeoffs encountered in building a production-quality compiler, A Retargetable C Compiler is also useful to individuals who work in application areas using or creating language-based tools and techniques. Features: discusses the implementation and design tradeoffs made while constructing a real ANSI C compiler, illustrating the interaction between theory and practice; covers compiler theory only as needed to understand the implementation of Icc, focusing instead on practical, applied issues; encourages a deeper understanding of programming in C, by providing C programmers with a tour of the language from the perspective of compiler authors; includes coverage of code generators for the MIPS R3000, SPARC, and Intel 386 and its successors; and provides access to the full source code for the Icc compiler, the three back ends, and the code-generator generator, either on disk or via FTP.}
}

@article{10.1145/390013.808479,
author = {Allen, Frances E.},
title = {Control flow analysis},
year = {1970},
issue_date = {July 1970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {7},
issn = {0362-1340},
url = {https://doi.org/10.1145/390013.808479},
doi = {10.1145/390013.808479},
abstract = {Any static, global analysis of the expression and data relationships in a program requires a knowledge of the control flow of the program. Since one of the primary reasons for doing such a global analysis in a compiler is to produce optimized programs, control flow analysis has been embedded in many compilers and has been described in several papers. An early paper by Prosser [5] described the use of Boolean matrices (or, more particularly, connectivity matrices) in flow analysis. The use of “dominance” relationships in flow analysis was first introduced by Prosser and much expanded by Lowry and Medlock [6]. References [6,8,9] describe compilers which use various forms of control flow analysis for optimization. Some recent developments in the area are reported in [4] and in [7].The underlying motivation in all the different types of control flow analysis is the need to codify the flow relationships in the program. The codification may be in connectivity matrices, in predecessor-successor tables, in dominance lists, etc. Whatever the form, the purpose is to facilitate determining what the flow relationships are; in other words to facilitate answering such questions as: is this an inner loop?, if an expression is removed from the loop where can it be correctly and profitably placed?, which variable definitions can affect this use?In this paper the basic control flow relationships are expressed in a directed graph. Various graph constructs are then found and shown to codify interesting global relationships.},
journal = {SIGPLAN Not.},
month = jul,
pages = {1–19},
numpages = {19}
}

@inbook{allen1970,
author = {Allen, Frances E.},
title = {Control flow analysis},
year = {1970},
isbn = {9781450373869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800028.808479},
doi = {10.1145/800028.808479},
abstract = {Any static, global analysis of the expression and data relationships in a program requires a knowledge of the control flow of the program. Since one of the primary reasons for doing such a global analysis in a compiler is to produce optimized programs, control flow analysis has been embedded in many compilers and has been described in several papers. An early paper by Prosser [5] described the use of Boolean matrices (or, more particularly, connectivity matrices) in flow analysis. The use of “dominance” relationships in flow analysis was first introduced by Prosser and much expanded by Lowry and Medlock [6]. References [6,8,9] describe compilers which use various forms of control flow analysis for optimization. Some recent developments in the area are reported in [4] and in [7].The underlying motivation in all the different types of control flow analysis is the need to codify the flow relationships in the program. The codification may be in connectivity matrices, in predecessor-successor tables, in dominance lists, etc. Whatever the form, the purpose is to facilitate determining what the flow relationships are; in other words to facilitate answering such questions as: is this an inner loop?, if an expression is removed from the loop where can it be correctly and profitably placed?, which variable definitions can affect this use?In this paper the basic control flow relationships are expressed in a directed graph. Various graph constructs are then found and shown to codify interesting global relationships.},
booktitle = {Proceedings of a Symposium on Compiler Optimization},
pages = {1–19},
numpages = {19},
location = {Urbana-Champaign, Illinois}
}

@inbook{amighi2012,
author="Amighi, Afshin
and de C. Gomes, Pedro
and Gurov, Dilian
and Huisman, Marieke",
editor="Eleftherakis, George
and Hinchey, Mike
and Holcombe, Mike",
title="Sound Control-Flow Graph Extraction for Java Programs with Exceptions",
booktitle="Software Engineering and Formal Methods",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="33--47",
isbn="978-3-642-33826-7",
doi="10.1007/978-3-642-33826-7_3"
}

@software{onnx,
  title = {Open Neural Network Exchange (ONNX)},
  author = {{ONNX Community}},
  year = {2019},
  url = {https://onnx.ai},
  urldate = {2025-07-07},
}

@inbook{dennis1974,
author="Dennis, Jack B.",
editor="Robinet, B.",
title="First version of a data flow procedure language",
booktitle="Programming Symposium",
year="1974",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="362--376",
abstract="A language for representing computational procedures based on the concept of data flow is presented in terms of a semantic model that permits concurrent execution of noninterfering program parts. Procedures in the language operate on elementary and structured values, and always define functional transformations of values. The language is equivalent in expressive power to a block structured language with internal procedure variables and is a generalization of pure Lisp. The language is being used as a model for study of fundamental semantic constructs for programming, as a target language for evaluating trans-latability of programs expressed at the user-language level, and as a guide for research in advanced computer architecture.",
isbn="978-3-540-37819-8"
}

@techreport{brock1979,
  author       = {Brock, J. Dean and Montz, Lynn B.},
  title        = {Translation and Optimization of Data Flow Programs},
  institution  = {Computation Structures Group, MIT CSAIL},
  type         = {Memo},
  number       = {Memo 181},
  address      = {Cambridge, MA, USA},
  month        = jul,
  year         = {1979},
  url          = {https://csg.csail.mit.edu/pubs/memos/Memo-181/Memo-181.pdf},
  urldate = {2025-07-07},
}

@ARTICLE{dennis1980,
  author={Dennis, Jack B.},
  journal={Computer}, 
  title={Data Flow Supercomputers}, 
  year={1980},
  volume={13},
  number={11},
  pages={48-56},
  keywords={Supercomputers;Computer architecture;Data flow computing;Concurrent computing;Large-scale systems;Computer languages;Application software},
  doi={10.1109/MC.1980.1653418}}

@article{ramsey2022,
author = {Ramsey, Norman},
title = {Beyond Relooper: recursive translation of unstructured control flow to structured control flow (functional pearl)},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {90},
url = {https://doi.org/10.1145/3547621},
doi = {10.1145/3547621},
journal = {Proc. ACM Program. Lang.},
month = aug,
articleno = {90},
numpages = {22},
keywords = {Haskell, WebAssembly, control-flow analysis, dominator tree, reverse postorder numbering}
}

@inbook{erosa1994,
  author={Erosa, A.M. and Hendren, L.J.},
  booktitle={Proceedings of 1994 IEEE International Conference on Computer Languages (ICCL'94)}, 
  title={Taming control flow: a structured approach to eliminating goto statements}, 
  year={1994},
  volume={},
  number={},
  pages={229-240},
  keywords={Program processors;Optimizing compilers;Programming profession;Switches;Computer science;Design optimization;Software testing;Software engineering;Information analysis;Flow graphs},
  doi={10.1109/ICCL.1994.288377}}

@inbook{weise1994,
author = {Weise, Daniel and Crew, Roger F. and Ernst, Michael and Steensgaard, Bjarne},
title = {Value dependence graphs: representation without taxation},
year = {1994},
isbn = {0897916360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/174675.177907},
doi = {10.1145/174675.177907},
abstract = {The value dependence graph (VDG) is a sparse dataflow-like representation that simplifies program analysis and transformation. It is a functional representation that represents control flow as data flow and makes explicit all machine quantities, such as stores and I/O channels. We are developing a compiler that builds a VDG representing a program, analyzes and transforms the VDG, then produces a control flow graph (CFG) [ASU86] from the optimized VDG. This framework simplifies transformations and improves upon several published results. For example, it enables more powerful code motion than [CLZ86, FOW87], eliminates as many redundancies as [AWZ88, RWZ88] (except for redundant loops), and provides important information to the code scheduler [BR91]. We exhibit a fast, one-pass method for elimination of partial redundancies that never performs redundant code motion [KFS92, DS93] and is simpler than the classical [MR79, Dha91] or SSA [RWZ88] methods. These results accrue from eliminating the CFG from the analysis/transformation phases and using demand dependences in preference to control dependences.},
booktitle = {Proceedings of the 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {297–310},
numpages = {14},
location = {Portland, Oregon, USA},
series = {POPL '94}
}

@inbook{weise1991,
author="Weise, Daniel
and Conybeare, Roland
and Ruf, Erik
and Seligman, Scott",
editor="Hughes, John",
title="Automatic online partial evaluation",
booktitle="Functional Programming Languages and Computer Architecture",
year="1991",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="165--191",
abstract="We have solved the problem of constructing a fully automatic online program specializer for an untyped functional language (specifically, the functional subset of Scheme). We designed our specializer, called Fuse, as an interpreter that returns a trace of suspended computations. The trace is represented as a graph, rather than as program text, and each suspended computation indicates the type of its result. A separate process translates the graph into a particular programming language. Producing graphs rather than program text solves problems with code duplication and premature reduce/residualize decisions. Fuse's termination strategy, which employs online generalization, specializes conditional recursive function calls, and unfolds all other calls. This strategy is shown to be both powerful and safe.",
isbn="978-3-540-47599-6",
doi="10.5555/645420.652530"
}

@inbook{tate2009,
author = {Tate, Ross and Stepp, Michael and Tatlock, Zachary and Lerner, Sorin},
title = {Equality saturation: a new approach to optimization},
year = {2009},
isbn = {9781605583792},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1480881.1480915},
doi = {10.1145/1480881.1480915},
abstract = {Optimizations in a traditional compiler are applied sequentially, with each optimization destructively modifying the program to produce a transformed program that is then passed to the next optimization. We present a new approach for structuring the optimization phase of a compiler. In our approach, optimizations take the form of equality analyses that add equality information to a common intermediate representation. The optimizer works by repeatedly applying these analyses to infer equivalences between program fragments, thus saturating the intermediate representation with equalities. Once saturated, the intermediate representation encodes multiple optimized versions of the input program. At this point, a profitability heuristic picks the final optimized program from the various programs represented in the saturated representation. Our proposed way of structuring optimizers has a variety of benefits over previous approaches: our approach obviates the need to worry about optimization ordering, enables the use of a global optimization heuristic that selects among fully optimized programs, and can be used to perform translation validation, even on compilers other than our own. We present our approach, formalize it, and describe our choice of intermediate representation. We also present experimental results showing that our approach is practical in terms of time and space overhead, is effective at discovering intricate optimization opportunities, and is effective at performing translation validation for a realistic optimizer.},
booktitle = {Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {264–276},
numpages = {13},
keywords = {compiler optimization, equality reasoning, intermediate representation},
location = {Savannah, GA, USA},
series = {POPL '09}
}

@inbook{stepp2011,
author="Stepp, Michael
and Tate, Ross
and Lerner, Sorin",
editor="Gopalakrishnan, Ganesh
and Qadeer, Shaz",
title="Equality-Based Translation Validator for LLVM",
booktitle="Computer Aided Verification",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="737--742",
abstract="We updated our Peggy tool, previously presented in [6], to perform translation validation for the LLVM compiler using a technique called Equality Saturation. We present the tool, and illustrate its effectiveness at doing translation validation on SPEC 2006 benchmarks.",
isbn="978-3-642-22110-1",
doi="10.1007/978-3-642-22110-1_59"
}

@inbook{tristan2011,
author = {Tristan, Jean-Baptiste and Govereau, Paul and Morrisett, Greg},
title = {Evaluating value-graph translation validation for LLVM},
year = {2011},
isbn = {9781450306638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1993498.1993533},
doi = {10.1145/1993498.1993533},
abstract = {Translation validators are static analyzers that attempt to verify that program transformations preserve semantics. Normalizing translation validators do so by trying to match the value-graphs of an original function and its transformed counterpart. In this paper, we present the design of such a validator for LLVM's intra-procedural optimizations, a design that does not require any instrumentation of the optimizer, nor any rewriting of the source code to compile, and needs to run only once to validate a pipeline of optimizations. We present the results of our preliminary experiments on a set of benchmarks that include GCC, a perl interpreter, SQLite3, and other C programs.},
booktitle = {Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {295–305},
numpages = {11},
keywords = {llvm, optimization, symbolic evaluation, translation validation},
location = {San Jose, California, USA},
series = {PLDI '11}
}

@inbook{johnson2003,
author="Johnson, Neil
and Mycroft, Alan",
editor="Hedin, Görel",
title="Combined Code Motion and Register Allocation Using the Value State Dependence Graph",
booktitle="Compiler Construction",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--16",
abstract="We define the Value State Dependence Graph (VSDG). The VSDG is a form of the Value Dependence Graph (VDG) extended by the addition of state dependence edges to model sequentialised computation. These express store dependencies and loop termination dependencies of the original program. We also exploit them to express the additional serialization inherent in producing final object code.",
isbn="978-3-540-36579-2",
doi="10.1007/3-540-36579-6_1"
}

@article{sharir1980,
title = {Structural analysis: A new approach to flow analysis in optimizing compilers},
journal = {Computer Languages},
volume = {5},
number = {3},
pages = {141-153},
year = {1980},
issn = {0096-0551},
doi = {10.1016/0096-0551(80)90007-7},
url = {https://www.sciencedirect.com/science/article/pii/0096055180900077},
author = {M. Sharir},
abstract = {In this paper we present a new technique for analyzing the control flow of a computer program. This technique, called structural analysis, extends new interval analysis techniques and produces a program representation in which structured control-flow patterns are detected and recorded. This representation supports data-flow analysis elimination techniques similar to Rosen's high-level data-flow analysis technique, which are faster than interval-based methods. Morever, these results indicate that flow-graph based program analysis and direct analysis of the program's parse-tree can be performed by essentially the same methods, making uniform data-flow analysis procedure for optimizing compilers possible.}
}

@webpage{stanier2023,
  author       = {James Stanier},
  title        = {Removing and Restoring Control Flow with the Value State Dependence Graph},
  school       = {University of Sussex},
  year         = {2023},
  url          = {https://sussex.figshare.com/articles/thesis/Removing_and_restoring_control_flow_with_the_Value_State_Dependence_Graph/23317190},
  urldate = {2025-07-07},
  note = {Doctoral thesis. University of Sussex, Sussex, United Kingdom.}
}

@inbook{johnson2004multiple,
author="Johnson, Neil
and Mycroft, Alan",
editor="Duesterwald, Evelyn",
title="Using Multiple Memory Access Instructions for Reducing Code Size",
booktitle="Compiler Construction",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="265--280",
abstract="An important issue in embedded systems design is the size of programs. As computing devices decrease in size, yet with more and more functions, better code size optimizations are in greater demand. For an embedded RISC processor, where the use of compact instructions (e.g., the ARM Thumb) restricts the number of accessible registers at the expense of a potential increase in spill code, a significant proportion of instructions load or store to memory.",
isbn="978-3-540-24723-4",
doi="10.1007/978-3-540-24723-4_18"
}

@article{ferrante1987,
author = {Ferrante, Jeanne and Ottenstein, Karl J. and Warren, Joe D.},
title = {The program dependence graph and its use in optimization},
year = {1987},
issue_date = {July 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
issn = {0164-0925},
url = {https://doi.org/10.1145/24039.24041},
doi = {10.1145/24039.24041},
abstract = {In this paper we present an intermediate program representation, called the program dependence graph (PDG), that makes explicit both the data and control dependences for each operation in a program. Data dependences have been used to represent only the relevant data flow relationships of a program. Control dependences are introduced to analogously represent only the essential control flow relationships of a program. Control dependences are derived from the usual control flow graph. Many traditional optimizations operate more efficiently on the PDG. Since dependences in the PDG connect computationally related parts of the program, a single walk of these dependences is sufficient to perform many optimizations. The PDG allows transformations such as vectorization, that previously required special treatment of control dependence, to be performed in a manner that is uniform for both control and data dependences. Program transformations that require interaction of the two dependence types can also be easily handled with our representation. As an example, an incremental approach to modifying data dependences resulting from branch deletion or loop unrolling is introduced. The PDG supports incremental optimization, permitting transformations to be triggered by one another and applied only to affected dependences.},
journal = {ACM Trans. Program. Lang. Syst.},
month = jul,
pages = {319–349},
numpages = {31}
}

@inbook{10.1145/178243.178258,
author = {Johnson, Richard and Pearson, David and Pingali, Keshav},
title = {The program structure tree: computing control regions in linear time},
year = {1994},
isbn = {089791662X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/178243.178258},
doi = {10.1145/178243.178258},
abstract = {In this paper, we describe the program structure tree (PST), a hierarchical representation of program structure based on single entry single exit (SESE) regions of the control flow graph. We give a linear-time algorithm for finding SESE regions and for building the PST of arbitrary control flow graphs (including irreducible ones). Next, we establish a connection between SESE regions and control dependence equivalence classes, and show how to use the algorithm to find control regions in linear time. Finally, we discuss some applications of the PST. Many control flow algorithms, such as construction of Static Single Assignment form, can be speeded up by applying the algorithms in a divide-and-conquer style to each SESE region on its own. The PST is also used to speed up data flow  analysis by exploiting “sparsity”. Experimental results from the Perfect Club and SPEC89 benchmarks confirm that the PST approach finds and exploits program structure.},
booktitle = {Proceedings of the ACM SIGPLAN 1994 Conference on Programming Language Design and Implementation},
pages = {171–185},
numpages = {15},
location = {Orlando, Florida, USA},
series = {PLDI '94}
}

@article{johnson1994,
author = {Johnson, Richard and Pearson, David and Pingali, Keshav},
title = {The program structure tree: computing control regions in linear time},
year = {1994},
issue_date = {June 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/773473.178258},
doi = {10.1145/773473.178258},
abstract = {In this paper, we describe the program structure tree (PST), a hierarchical representation of program structure based on single entry single exit (SESE) regions of the control flow graph. We give a linear-time algorithm for finding SESE regions and for building the PST of arbitrary control flow graphs (including irreducible ones). Next, we establish a connection between SESE regions and control dependence equivalence classes, and show how to use the algorithm to find control regions in linear time. Finally, we discuss some applications of the PST. Many control flow algorithms, such as construction of Static Single Assignment form, can be speeded up by applying the algorithms in a divide-and-conquer style to each SESE region on its own. The PST is also used to speed up data flow  analysis by exploiting “sparsity”. Experimental results from the Perfect Club and SPEC89 benchmarks confirm that the PST approach finds and exploits program structure.},
journal = {SIGPLAN Not.},
month = jun,
pages = {171–185},
numpages = {15}
}

@article{10.1145/202530.202534,
author = {Click, Cliff and Paleczny, Michael},
title = {A simple graph-based intermediate representation},
year = {1995},
issue_date = {March 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3},
issn = {0362-1340},
url = {https://doi.org/10.1145/202530.202534},
doi = {10.1145/202530.202534},
abstract = {We present a graph-based intermediate representation (IR) with simple semantics and a low-memory-cost C++ implementation. The IR uses a directed graph with labeled vertices and ordered inputs but unordered outputs. Vertices are labeled with opcodes, edges are unlabeled. We represent the CFG and basic blocks with the same vertex and edge structures. Each opcode is defined by a C++ class that encapsulates opcode-specific data and behavior. We use inheritance to abstract common opcode behavior, allowing new opcodes to be easily defined from old ones. The resulting IR is simple, fast and easy to use.},
journal = {SIGPLAN Not.},
month = mar,
pages = {35–49},
numpages = {15}
}

@inbook{click1995,
author = {Click, Cliff and Paleczny, Michael},
title = {A simple graph-based intermediate representation},
year = {1995},
isbn = {0897917545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/202529.202534},
doi = {10.1145/202529.202534},
abstract = {We present a graph-based intermediate representation (IR) with simple semantics and a low-memory-cost C++ implementation. The IR uses a directed graph with labeled vertices and ordered inputs but unordered outputs. Vertices are labeled with opcodes, edges are unlabeled. We represent the CFG and basic blocks with the same vertex and edge structures. Each opcode is defined by a C++ class that encapsulates opcode-specific data and behavior. We use inheritance to abstract common opcode behavior, allowing new opcodes to be easily defined from old ones. The resulting IR is simple, fast and easy to use.},
booktitle = {Papers from the 1995 ACM SIGPLAN Workshop on Intermediate Representations},
pages = {35–49},
numpages = {15},
location = {San Francisco, California, USA},
series = {IR '95}
}

@webpage{steensgaard1993,
  title={Sequentializing program dependence graphs for irreducible programs},
  author={Steensgaard, Bjarne},
  year={1993},
  publisher={Citeseer},
  url={https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=a0d78dc17daca1c56e6c999ad27351d291d09754},
  urldate = {2025-07-07},
  note = {Technical Report Number: MSR-TR-93-14, Microsoft Research, Redmond, Washington, United States}
}

@inbook{baxter1989,
author = {Baxter, W. and Bauer, H. R.},
title = {The program dependence graph and vectorization},
year = {1989},
isbn = {0897912942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75277.75278},
doi = {10.1145/75277.75278},
abstract = {Previous attempts at vectorizing programs written in a sequential high level language focused on converting control dependences to data dependences using a mechanism known as IF-conversion. After IF-conversion vector optimizations are performed on a data dependence graph. However, IF-conversion is an irrevocable process which can introduce high run-time overhead if the input program is not amenable to vectorization.This paper uses a program dependence graph as the intermediate representation for a vectorizing compiler. A program dependence graph explicitly represents both control and data dependences, allowing guard values to be generated for vectorized statements. Techniques have been developed to perform code motion on vectorization candidates, to validly eliminate all unnecessary control and data dependence cycles, and to regenerate the newly vectorized program consistent with a topological ordering based on the control and data dependences.},
booktitle = {Proceedings of the 16th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {1–11},
numpages = {11},
location = {Austin, Texas, USA},
series = {POPL '89}
}

@ARTICLE{sarkar1991,
  author={Sarkar, V.},
  journal={IBM Journal of Research and Development}, 
  title={Automatic partitioning of a program dependence graph into parallel tasks}, 
  year={1991},
  volume={35},
  number={5.6},
  pages={779-804},
  keywords={},
  doi={10.1147/rd.355.0779}}

@inbook{ferrante1985,
author = {Ferrante, Jeanne and Mace, Mary},
title = {On linearizing parallel code},
year = {1985},
isbn = {0897911474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/318593.318636},
doi = {10.1145/318593.318636},
abstract = {We consider the problem of generating sequential code for programs written in a language which contains a Multiple GOTO operator, predicates and statements. This problem arises when compiling a parallel intermediate form (such as the PDG [3,4]) to run on a sequential machine; in a source-to-source FORTRAN translator when vectorization of a loop has failed; and when compiling logic designs written in a parallel design language for simulation on a sequential machine. It is easy to generate sequential code for this sort of parallel program if one allows either duplication of code or the insertion of guard variables at merge points; in fact, it is in general impossible without this addition. However, for a large class of parallel programs (such as those originally arising from sequential programs, even after some optimizations have been applied) it is possible to generate sequential code without duplication or the addition of guard variables. In this paper we present an efficient algorithm which will generate sequential code from a parallel program without duplication or additional guard variables for a large class of parallel programs.},
booktitle = {Proceedings of the 12th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
pages = {179–190},
numpages = {12},
location = {New Orleans, Louisiana, USA},
series = {POPL '85}
}

@inbook{10.1145/93542.93578,
author = {Ottenstein, Karl J. and Ballance, Robert A. and MacCabe, Arthur B.},
title = {The program dependence web: a representation supporting control-, data-, and demand-driven interpretation of imperative languages},
year = {1990},
isbn = {0897913647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/93542.93578},
doi = {10.1145/93542.93578},
abstract = {The Program Dependence Web (PDW) is a program representation that can be directly interpreted using control-, data-, or demand-driven models of execution. A PDW combines a single-assignment version of the program with explicit operators that manage the flow of data values. The PDW can be viewed as an augmented Program Dependence Graph. Translation to the PDW representation provides the basis for projects to compile Fortran onto dynamic dataflow architectures and simulators. A second application of the PDW is the construction of various compositional semantics for program dependence graphs.},
booktitle = {Proceedings of the ACM SIGPLAN 1990 Conference on Programming Language Design and Implementation},
pages = {257–271},
numpages = {15},
location = {White Plains, New York, USA},
series = {PLDI '90}
}

@article{ottenstein1990,
author = {Ottenstein, Karl J. and Ballance, Robert A. and MacCabe, Arthur B.},
title = {The program dependence web: a representation supporting control-, data-, and demand-driven interpretation of imperative languages},
year = {1990},
issue_date = {Jun. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/93548.93578},
doi = {10.1145/93548.93578},
abstract = {The Program Dependence Web (PDW) is a program representation that can be directly interpreted using control-, data-, or demand-driven models of execution. A PDW combines a single-assignment version of the program with explicit operators that manage the flow of data values. The PDW can be viewed as an augmented Program Dependence Graph. Translation to the PDW representation provides the basis for projects to compile Fortran onto dynamic dataflow architectures and simulators. A second application of the PDW is the construction of various compositional semantics for program dependence graphs.},
journal = {SIGPLAN Not.},
month = jun,
pages = {257–271},
numpages = {15}
}

@inbook{pingali1991,
author = {Pingali, Keshav and Beck, Micah and Johnson, Richard and Moudgill, Mayan and Stodghill, Paul},
title = {Dependence flow graphs: an algebraic approach to program dependencies},
year = {1991},
isbn = {0897914198},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/99583.99595},
doi = {10.1145/99583.99595},
booktitle = {Proceedings of the 18th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {67–78},
numpages = {12},
location = {Orlando, Florida, USA},
series = {POPL '91}
}

@inbook{10.1145/155090.155098,
author = {Johnson, Richard and Pingali, Keshav},
title = {Dependence-based program analysis},
year = {1993},
isbn = {0897915984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/155090.155098},
doi = {10.1145/155090.155098},
abstract = {Program analysis and optimization can be speeded up through the use of the dependence flow graph (DFG), a representation of program dependences which generalizes def-use chains and static single assignment (SSA) form. In this paper, we give a simple graph-theoretic description of the DFG and show how the DFG for a program can be constructed in O(EV) time. We then show how forward and backward dataflow analyses can be performed efficiently on the DFG, using constant propagation and elimination of partial redundancies as examples. These analyses can be framed as solutions of dataflow equations in the DFG. Our construction algorithm is of independent interest because it can be used to construct a program's control dependence graph in O(E) time and its SSA representation in O(EV) time, which are improvements over existing algorithms.},
booktitle = {Proceedings of the ACM SIGPLAN 1993 Conference on Programming Language Design and Implementation},
pages = {78–89},
numpages = {12},
location = {Albuquerque, New Mexico, USA},
series = {PLDI '93}
}

@article{johnson1993,
author = {Johnson, Richard and Pingali, Keshav},
title = {Dependence-based program analysis},
year = {1993},
issue_date = {June 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/173262.155098},
doi = {10.1145/173262.155098},
abstract = {Program analysis and optimization can be speeded up through the use of the dependence flow graph (DFG), a representation of program dependences which generalizes def-use chains and static single assignment (SSA) form. In this paper, we give a simple graph-theoretic description of the DFG and show how the DFG for a program can be constructed in O(EV) time. We then show how forward and backward dataflow analyses can be performed efficiently on the DFG, using constant propagation and elimination of partial redundancies as examples. These analyses can be framed as solutions of dataflow equations in the DFG. Our construction algorithm is of independent interest because it can be used to construct a program's control dependence graph in O(E) time and its SSA representation in O(EV) time, which are improvements over existing algorithms.},
journal = {SIGPLAN Not.},
month = jun,
pages = {78–89},
numpages = {12}
}

@inbook{lafont1989,
author = {Lafont, Yves},
title = {Interaction nets},
year = {1989},
isbn = {0897913434},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/96709.96718},
doi = {10.1145/96709.96718},
booktitle = {Proceedings of the 17th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {95–108},
numpages = {14},
location = {San Francisco, California, USA},
series = {POPL '90}
}

@software{HVM,
  author       = {{HigherOrderCO}},
  title        = {{HVM: A Virtual Machine for Interaction Nets}},
  url = {https://github.com/HigherOrderCO/HVM},
  year         = {2025},
  urldate = {2025-07-07},
}

@webpage{tiobe2025,
  author       = {{TIOBE Software BV}},
  title        = {TIOBE Index for July 2025},
  year         = {2025},
  url = {https://web.archive.org/web/20250709134336/https://www.tiobe.com/tiobe-index/},
  urldate = {2025-07-08},
}

@software{githut2024,
  author       = {Madnight},
  title        = {GitHut 2.0 – GitHub Language Statistics (Q1 2024)},
  year         = {2024},
  url = {https://madnight.github.io/githut/#/pushes/2024/1},
  urldate = {2025-07-08},
}

@software{rapidfuzz,
  author       = {Max Bachmann},
  title        = {RapidFuzz: Fuzzy String Matching in Python},
  year         = {2021},
  url = {https://github.com/rapidfuzz/RapidFuzz},
  urldate = {2025-07-08},
}

@inbook{hasabnis2016,
author = {Hasabnis, Niranjan and Sekar, R.},
title = {Lifting Assembly to Intermediate Representation: A Novel Approach Leveraging Compilers},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872380},
doi = {10.1145/2872362.2872380},
abstract = {Translating low-level machine instructions into higher-level intermediate language (IL) is one of the central steps in many binary analysis and instrumentation systems. Existing systems build such translators manually. As a result, it takes a great deal of effort to support new architectures. Even for widely deployed architectures, full instruction sets may not be modeled, e.g., mature systems such as Valgrind still lack support for AVX, FMA4 and SSE4.1 for x86 processors. To overcome these difficulties, we propose a novel approach that leverages knowledge about instruction set semantics that is already embedded into modern compilers such as GCC. In particular, we present a learning-based approach for automating the translation of assembly instructions to a compiler's architecture-neutral IL. We present an experimental evaluation that demonstrates the ability of our approach to easily support many architectures (x86, ARM and AVR), including their advanced instruction sets. Our implementation is available as open-source software.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {311–324},
numpages = {14},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inbook{sahasrabuddhe2007,
  author={Sahasrabuddhe, Sameer D. and Raja, Hakim and Arya, Kavi and Desai, Madhav P.},
  booktitle={20th International Conference on VLSI Design held jointly with 6th International Conference on Embedded Systems (VLSID'07)}, 
  title={AHIR: A Hardware Intermediate Representation for Hardware Generation from High-level Programs}, 
  year={2007},
  volume={},
  number={},
  pages={245-250},
  keywords={Hardware;Optimizing compilers;Timing;Computer languages;Programming profession;Digital signal processing;Flow graphs;Very large scale integration;Microprocessors;Field programmable gate arrays},
  doi={10.1109/VLSID.2007.28}}

@inbook{Kirchner2017,
author = {Kirchner, Kevin and Rosenthaler, Stefan},
title = {bin2llvm: Analysis of Binary Programs Using LLVM Intermediate Representation},
year = {2017},
isbn = {9781450352574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3098954.3103152},
doi = {10.1145/3098954.3103152},
abstract = {The analysis of programs is an important and well researched topic in information security, specifically for finding bugs in binary programs or analyzing malicious software. Many commonly used techniques rely on dynamic analysis by running samples and monitoring their behavior or are based on the cumbersome and time consuming inspection of plain assembly code.In this paper we present a novel approach for static analysis we are using in bin2llvm, a work-in-progress analysis framework, in order to find and identify cryptographic routines in binary programs. Our approach does not need to run the target of analysis in any way and is based on decompilation of binaries to an intermediate language similar to assembly code, the LLVM Intermediate Representation (IR), by using the open source decompiler Dagger. After decompilation we are able to apply various analysis techniques to the resulting code. These methods can be easily implemented and extended as optimization passes for the LLVM optimizer and can therefore benefit from its extensive API. Although we discovered certain drawbacks and issues with this approach, our results and proof of concept show that IR code is a very suitable target for analyses and it is well worth driving research further into this topic.},
booktitle = {Proceedings of the 12th International Conference on Availability, Reliability and Security},
articleno = {45},
numpages = {7},
keywords = {Analysis, Binary, Cryptography, Decompiler, Intermediate Representation, LLVM},
location = {Reggio Calabria, Italy},
series = {ARES '17}
}

@inbook{liu2010,
  author={Liu, Xuying and Yin, Wenjian and Yin, Qing and Jiang, Liehui},
  booktitle={2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering}, 
  title={A SSA-based intermediate representation technique}, 
  year={2010},
  volume={6},
  number={},
  pages={98-101},
  keywords={Registers;BRIL;Binary Reverse Intermediate Language;SSA;Decompilation;Intermediate Language},
  doi={10.1109/CMCE.2010.5609916}}

@inbook{santhanam2021,
author = {Santhanam, Keshav and Krishna, Siddharth and Tomioka, Ryota and Fitzgibbon, Andrew and Harris, Tim},
title = {DistIR: An Intermediate Representation for Optimizing Distributed Neural Networks},
year = {2021},
isbn = {9781450382984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437984.3458829},
doi = {10.1145/3437984.3458829},
abstract = {The rapidly growing size of deep neural network (DNN) models and datasets has given rise to a variety of distribution strategies such as data, horizontal, and pipeline parallelism. However, selecting the best set of strategies for a given model and hardware configuration is challenging because debugging and testing on clusters is expensive. In this work we propose DistIR, an IR for explicitly representing distributed DNN computation that can capture many popular distribution strategies. We build an analysis framework for DistIR programs, including a simulator and reference executor that can be used to automatically search for an optimal distribution strategy. Our unified global representation also eases development of new distribution strategies, as one can reuse the lowering to per-rank backend programs. Preliminary results using a grid search over a hybrid data/horizontal/pipeline-parallel space suggest DistIR and its simulator can aid automatic DNN distribution.},
booktitle = {Proceedings of the 1st Workshop on Machine Learning and Systems},
pages = {15–23},
numpages = {9},
keywords = {distributed computation, intermediate representation, neural networks, optimization},
location = {Online, United Kingdom},
series = {EuroMLSys '21}
}

@article{kunft2019,
author = {Kunft, Andreas and Katsifodimos, Asterios and Schelter, Sebastian and Bress, Sebastian and Rabl, Tilmann and Markl, Volker},
title = {An intermediate representation for optimizing machine learning pipelines},
year = {2019},
issue_date = {July 2019},
publisher = {VLDB Endowment},
volume = {12},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3342263.3342633},
doi = {10.14778/3342263.3342633},
abstract = {Machine learning (ML) pipelines for model training and validation typically include preprocessing, such as data cleaning and feature engineering, prior to training an ML model. Preprocessing combines relational algebra and user-defined functions (UDFs), while model training uses iterations and linear algebra. Current systems are tailored to either of the two. As a consequence, preprocessing and ML steps are optimized in isolation. To enable holistic optimization of ML training pipelines, we present Lara, a declarative domain-specific language for collections and matrices. Lara's inter-mediate representation (IR) reflects on the complete program, i.e., UDFs, control flow, and both data types. Two views on the IR enable diverse optimizations. Monads enable operator pushdown and fusion across type and loop boundaries. Combinators provide the semantics of domain-specific operators and optimize data access and cross-validation of ML algorithms. Our experiments on preprocessing pipelines and selected ML algorithms show the effects of our proposed optimizations on dense and sparse data, which achieve speedups of up to an order of magnitude.},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {1553–1567},
numpages = {15}
}

@article{cyphers2018,
      title={Intel nGraph: An Intermediate Representation, Compiler, and Executor for Deep Learning}, 
      author={Scott Cyphers and Arjun K. Bansal and Anahita Bhiwandiwalla and Jayaram Bobba and Matthew Brookhart and Avijit Chakraborty and Will Constable and Christian Convey and Leona Cook and Omar Kanawi and Robert Kimball and Jason Knight and Nikolay Korovaiko and Varun Kumar and Yixing Lao and Christopher R. Lishka and Jaikrishnan Menon and Jennifer Myers and Sandeep Aswath Narayana and Adam Procter and Tristan J. Webb},
      year={2018},
      eprint={1801.08058},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/1801.08058}, 
      doi={10.48550/arXiv.1801.08058}
      
}

﻿@Article{Cardama2025,
author={Cardama, F. Javier
and Vázquez-Pérez, Jorge
and Piñeiro, César
and Pichel, Juan C.
and Pena, Tomás F.
and Gómez, Andrés},
title={Review of intermediate representations for quantum computing},
journal={The Journal of Supercomputing},
year={2025},
month={Jan},
day={21},
volume={81},
number={2},
pages={418},
issn={1573-0484},
doi={10.1007/s11227-024-06892-2},
url={https://doi.org/10.1007/s11227-024-06892-2}
}

@software{gimple,
  author    = {Jason Merrill},
  title     = {GENERIC and GIMPLE: A New Tree Representation for Entire Functions},
  year      = {2003},
  url       = {https://ftp.cygwin.com/pub/gcc/summit/2003/GENERIC%20and%20GIMPLE.pdf},
  urldate = {2025-07-09},
}

@software{crossref,
  title        = {Crossref REST API Documentation},
  author       = {{Crossref}},
  year         = {2025},
  url          = {https://www.crossref.org/documentation/retrieve-metadata/rest-api/},
  urldate = {2025-7-9}, 
}

@software{knill2014,
  author       = {Oliver Knill},
  title        = {Ambiguity in Mathematical Notation},
  year         = {2014},
  url = {https://people.math.harvard.edu/~knill/pedagogy/ambiguity/index.html},
  urldate = {2025-7-9}, 
}

@webpage{stauffer1978,
  author       = {Stauffer, J D},
  title        = {LCL:  a compiler and language for logical mask checking},
  institution  = {Sandia Labs., Albuquerque, N.Mex. (USA)},
  url          = {https://www.osti.gov/biblio/6758481},
  urldate = {25-8-7},
  place        = {United States},
  year         = {1978},
  month        = {03},
  note = {Technical Report Number: 6758481, Sandia Labs., Albuquerque, N.Mex. (USA)},
}

@inbook{10.1145/202529.202541,
author = {Gosling, James},
title = {Java intermediate bytecodes: ACM SIGPLAN workshop on intermediate representations (IR'95)},
year = {1995},
isbn = {0897917545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/202529.202541},
doi = {10.1145/202529.202541},
abstract = {Java is a programming language loosely related to C++. Java originated in a project to produce a software development environment for small distributed embedded systems. Programs needed to be small, fast, “safe” and portable. These needs led to a design that is rather different from standard practice. In particular, the form of compiled programs is machine independent bytecodes. But we needed to manipulate programs in ways usually associated with higher level, more abstract intermediate representations. This lets us build systems that are safer, less fragile, more portable, and yet show little performance penalty while still being simple.},
booktitle = {Papers from the 1995 ACM SIGPLAN Workshop on Intermediate Representations},
pages = {111–118},
numpages = {8},
location = {San Francisco, California, USA},
series = {IR '95}
}

@article{gosling1995,
author = {Gosling, James},
title = {Java intermediate bytecodes: ACM SIGPLAN workshop on intermediate representations (IR'95)},
year = {1995},
issue_date = {March 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3},
issn = {0362-1340},
url = {https://doi.org/10.1145/202530.202541},
doi = {10.1145/202530.202541},
abstract = {Java is a programming language loosely related to C++. Java originated in a project to produce a software development environment for small distributed embedded systems. Programs needed to be small, fast, “safe” and portable. These needs led to a design that is rather different from standard practice. In particular, the form of compiled programs is machine independent bytecodes. But we needed to manipulate programs in ways usually associated with higher level, more abstract intermediate representations. This lets us build systems that are safer, less fragile, more portable, and yet show little performance penalty while still being simple.},
journal = {SIGPLAN Not.},
month = mar,
pages = {111–118},
numpages = {8}
}

@inbook{cytron1986,
author = {Cytron, Ron and Lowry, Andy and Zadeck, F. Kenneth},
title = {Code motion of control structures in high-level languages},
year = {1986},
isbn = {9781450373470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/512644.512651},
doi = {10.1145/512644.512651},
abstract = {One trend among programmers is the increased use of abstractions. Through encapsulation techniques, abstractions extend the repertory of data structures and their concomitant operations that are processed directly by a compiler. For example, a compiler might not offer sets or set operations in its base language, but abstractions allow a programmer to define sets in terms of constructs already recognized by the compiler. In particular, abstractions can allow new constructs to be defined in terms of other abstractions. Although significant power is gained through the use of layered abstractions, object code quality suffers as increasingly less of a program's data structures and operations are exposed to the optimization phase of a compiler. Multiple references to abstractions are also inefficient, since the interaction between abstractions is often complex yet hidden from a compiler. Abstractions are most flexible when they are cast in general terms; a specific invocation is then tailored by the abstraction to obtain the appropriate code. A sequence of references to such abstractions can be inefficient due to functional redundancy that cannot be detected at compile-time. By integrating the references, the offending segments of code can be moved to a more advantageous position. Although procedure integration materializes abstracted constructs, the abstractions can still be ineligible for optimization using current techniques; in particular, abstractions often involve loops and conditional branches that can obscure code that would otherwise be eligible for code motion.},
booktitle = {Proceedings of the 13th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
pages = {70–85},
numpages = {16},
location = {St. Petersburg Beach, Florida},
series = {POPL '86}
}

@article{cytron1991,
author = {Cytron, Ron and Ferrante, Jeanne and Rosen, Barry K. and Wegman, Mark N. and Zadeck, F. Kenneth},
title = {Efficiently computing static single assignment form and the control dependence graph},
year = {1991},
issue_date = {Oct. 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {0164-0925},
url = {https://doi.org/10.1145/115372.115320},
doi = {10.1145/115372.115320},
journal = {ACM Trans. Program. Lang. Syst.},
month = oct,
pages = {451–490},
numpages = {40},
keywords = {optimizing compilers, dominator, def-use chain, control flow graph, control dependence}
}

@inbook{boissinot2009,
  author={Boissinot, Benoit and Darte, Alain and Rastello, Fabrice and de Dinechin, Benoit Dupont and Guillon, Christophe},
  booktitle={2009 International Symposium on Code Generation and Optimization}, 
  title={Revisiting Out-of-SSA Translation for Correctness, Code Quality and Efficiency}, 
  year={2009},
  volume={},
  number={},
  pages={114-125},
  keywords={Interference;Optimizing compilers;Algorithm design and analysis;Program processors;Constraint optimization;Design optimization;Costs;Code standards;Flow graphs;Tree graphs;SSA form;Compilers;JIT-compilation},
  doi={10.1109/CGO.2009.19}}

@webpage{yang1989,
  author    = {Wuu Yang and Susan Horwitz and Thomas Reps},
  title     = {Detecting Program Components With Equivalent Behaviors},
  institution = {University of Wisconsin-Madison Department of Computer Sciences},
  year      = {1989},
  number    = {TR840},
  url       = {https://minds.wisconsin.edu/handle/1793/59110},
  urldate = {2025-7-9},
}

@inbook{rosen1988,
author = {Rosen, B. K. and Wegman, M. N. and Zadeck, F. K.},
title = {Global value numbers and redundant computations},
year = {1988},
isbn = {0897912527},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/73560.73562},
doi = {10.1145/73560.73562},
booktitle = {Proceedings of the 15th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {12–27},
numpages = {16},
location = {San Diego, California, USA},
series = {POPL '88}
}

@article{wegman1991,
author = {Wegman, Mark N. and Zadeck, F. Kenneth},
title = {Constant propagation with conditional branches},
year = {1991},
issue_date = {April 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0164-0925},
url = {https://doi.org/10.1145/103135.103136},
doi = {10.1145/103135.103136},
abstract = {Constant propagation is a well-known global flow analysis problem. The goal of constant propagation is to discover values that are constant on all possible executions of a program and to propagate these constant values as far foward through the program as possible. Expressions whose operands are all constants can be evaluated at compile time and the results propagated further. Using the algorithms presented in this paper can produce smaller and faster compiled programs. The same algorithms can be used for other kinds of analyses (e.g., type of determination). We present four algorithms in this paper, all conservitive in the sense that all constants may not be found, but each constant found is constant over all possible executions of the program. These algorithms are among the simplest, fastest, and most powerful global constant propagation algorithms known. We also present a new algorithm that performs a form of interprocedural data flow analysis in which aliasing information is gathered in conjunction with constant progagation. Several variants of this algorithm are considered.},
journal = {ACM Trans. Program. Lang. Syst.},
month = apr,
pages = {181–210},
numpages = {30},
keywords = {abstract interpretation, code optimization, constant propagation, control flow graph, interprocedural analysis, procedure integration, static single assignment form, type determination}
}

@inbook{lattner2021,
  author={Lattner, Chris and Amini, Mehdi and Bondhugula, Uday and Cohen, Albert and Davis, Andy and Pienaar, Jacques and Riddle, River and Shpeisman, Tatiana and Vasilache, Nicolas and Zinenko, Oleksandr},
  booktitle={2021 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)}, 
  title={MLIR: Scaling Compiler Infrastructure for Domain Specific Computation}, 
  year={2021},
  volume={},
  number={},
  pages={2-14},
  keywords={Program processors;Buildings;Semantics;Hardware;Software;Generators;Optimization},
  doi={10.1109/CGO51591.2021.9370308}}

@book{church1941,
title     = "The calculi of lambda conversion.",
  author    = "{Alonzo Church}",
  publisher = "Princeton University Press",
  series    = "Annals of Mathematics Studies",
  month     =  aug,
  year      =  1941,
  address   = "Princeton, NJ",
  language  = "en",
  isbn = "978-0691083940"
}


@inbook{stoltz1994,
  author={Stoltz and Gerlek and Wolfe},
  booktitle={1994 Proceedings of the Twenty-Seventh Hawaii International Conference on System Sciences}, 
  title={Extended SSA with factored use-def chains to support optimization and parallelism}, 
  year={1994},
  volume={2},
  number={},
  pages={43-52},
  keywords={Parallel programming;FORTRAN;Parallel languages;Compilers;Optimization methods},
  doi={10.1109/HICSS.1994.323280}}

@article{grosser2012,
  author = {Grosser, Tobias and Groesslinger, Armin and Lengauer, Christian},
  title = {Polly — Performing Polyhedral Optimizations on a Low-Level Intermediate Representation},
  journal = {Parallel Processing Letters},
  volume = {22},
  number = {04},
  pages = {1250010},
  year = {2012},
  doi = {10.1142/S0129626412500107},
}

@article{tarjan1981,
author = {Tarjan, Robert Endre},
title = {A Unified Approach to Path Problems},
year = {1981},
issue_date = {July 1981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {3},
issn = {0004-5411},
url = {https://doi.org/10.1145/322261.322272},
doi = {10.1145/322261.322272},
journal = {J. ACM},
month = jul,
pages = {577–593},
numpages = {17}
}

@article{tarjan1979,
author = {Tarjan, Robert Endre},
title = {Applications of Path Compression on Balanced Trees},
year = {1979},
issue_date = {Oct. 1979},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {4},
issn = {0004-5411},
url = {https://doi.org/10.1145/322154.322161},
doi = {10.1145/322154.322161},
journal = {J. ACM},
month = oct,
pages = {690–715},
numpages = {26}
}

@article{tu1995,
author = {Tu, Peng and Padua, David},
title = {Efficient building and placing of gating functions},
year = {1995},
issue_date = {June 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/223428.207115},
doi = {10.1145/223428.207115},
abstract = {In this paper, we present an almost-linear time algorithm for constructing Gated Single Assignment (GSA), which is SSA augmented with gating functions at \o{}-nodes. The gating functions specify the control dependences for each reaching definition at a \o{}-node. We introduce a new concept of gating path, which is path in the control flow graph from the immediate dominator u of a node v to v, such that every node in the path is dominated by u. Previous algorithms start with \o{}-function placement, and then traverse the control flow graph to compute the gating functions. By formulating the problem into gating path construction, we are able to identify not only a \o{}-node, but also a gating path expression which defines a gating function for the \o{}-node.},
journal = {SIGPLAN Not.},
month = jun,
pages = {47–55},
numpages = {9}
}

@inbook{havlak1994,
author="Havlak, Paul",
editor="Banerjee, Utpal
and Gelernter, David
and Nicolau, Alex
and Padua, David",
title="Construction of thinned gated single-assignment form",
booktitle="Languages and Compilers for Parallel Computing",
year="1994",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="477--499",
abstract="Analysis of symbolic expressions benefits from a suitable program representation. We show how to build thinned gated single-assignment (TGSA) form, a value-oriented program representation which is more complete than standard SSA form, defined on all reducible programs, and better for representing symbolic expressions than program dependence graphs or original GSA form. We present practical algorithms for constructing thinned GSA form from the control dependence graph and SSA form. Extensive experiments on large Fortran programs show these methods to take linear time and space in practice. Our implementation of value numbering on TGSA form drives scalar symbolic analysis in the ParaScope programming environment.",
isbn="978-3-540-48308-3",
doi="10.1007/3-540-57659-2_28"
}

@inbook{wolfe1992,
author = {Wolfe, Michael},
title = {Beyond induction variables},
year = {1992},
isbn = {0897914759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/143095.143131},
doi = {10.1145/143095.143131},
abstract = {Induction variable detection is usually closely tied to the strength reduction optimization. This paper studies induction variable analysis from a different perspective, that of finding induction variables for data dependence analysis. While classical induction variable analysis techniques have been used successfully up to now, we have found a simple algorithm based on the Static Single Assignment form of a program that finds all linear induction variables in a loop. Moreover, this algorithm is easily extended to find induction variables in multiple nested loops, to find nonlinear induction variables, and to classify other integer scalar assignments in loops, such as monotonic, periodic and wrap-around variables. Some of these other variables are now classified using ad hoc pattern recognition, while others are not analyzed by current compilers. Giving a unified approach improves the speed of compilers and allows a more general classification scheme. We also show how to use these variables in data dependence testing.},
booktitle = {Proceedings of the ACM SIGPLAN 1992 Conference on Programming Language Design and Implementation},
pages = {162–174},
numpages = {13},
location = {San Francisco, California, USA},
series = {PLDI '92}
}

@article{gerlek1995,
author = {Gerlek, Michael P. and Stoltz, Eric and Wolfe, Michael},
title = {Beyond induction variables: detecting and classifying sequences using a demand-driven SSA form},
year = {1995},
issue_date = {Jan. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {1},
issn = {0164-0925},
url = {https://doi.org/10.1145/200994.201003},
doi = {10.1145/200994.201003},
abstract = {Linear induction variable detection is usually associated with the strength reduction optimization. For restructuring compilers, effective data dependence analysis requires that the compiler detect and accurately describe linear and nonlinear induction variables as well as more general sequences. In this article we present a practical technique for detecting a broader class of linear induction variables than is usually recognized, as well as several other sequence forms, including periodic, polynomial, geometric, monotonic, and wrap-around variables. Our method is based on Factored Use-Def (FUD) chains, a demand-driven representation of the popular Static Single Assignment (SSA) form. In this form, strongly connected components of the associated SSA graph correspond to sequences in the source program: we describe a simple yet efficient algorithm for detecting and classifying these sequences. We have implemented this algorithm in Nascent, our restructuring Fortran 90+ compiler, and we present some results showing the effectiveness of our approach.},
journal = {ACM Trans. Program. Lang. Syst.},
month = jan,
pages = {85–122},
numpages = {38},
keywords = {wraparound variable, strength reduction, static single assignment, induction variable, demand-driven, def-use chain, constant propagation}
}

@article{ebner2008,
author = {Ebner, Dietmar and Brandner, Florian and Scholz, Bernhard and Krall, Andreas and Wiedermann, Peter and Kadlec, Albrecht},
title = {Generalized instruction selection using SSA-graphs},
year = {2008},
issue_date = {July 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {7},
issn = {0362-1340},
url = {https://doi.org/10.1145/1379023.1375663},
doi = {10.1145/1379023.1375663},
abstract = {Instruction selection is a well-studied compiler phase that translates the compiler's intermediate representation of programs to a sequence of target-dependent machine instructions optimizing for various compiler objectives (e.g. speed and space). Most existing instruction selection techniques are limited to the scope of a single statement or a basic block and cannot cope with irregular instruction sets that are frequently found in embedded systems.We consider an optimal technique for instruction selection that uses Static Single Assignment (SSA) graphs as an intermediate representation of programs and employs the Partitioned Boolean Quadratic Problem (PBQP) for finding an optimal instruction selection. While existing approaches are limited to instruction patterns that can be expressed in a simple tree structure, we consider complex patterns producing multiple results at the same time including pre/post increment addressing modes, div-mod instructions, and SIMD extensions frequently found in embedded systems. Although both instruction selection on SSA-graphs and PBQP are known to be NP-complete, the problem can be solved efficiently - even for very large instances.Our approach has been implemented in LLVM for an embedded ARMv5 architecture. Extensive experiments show speedups of up to 57\% on typical DSP kernels and up to 10\% on SPECINT 2000 and MiBench benchmarks. All of the test programs could be compiled within less than half a minute using a heuristic PBQP solver that solves 99.83\% of all instances optimally.},
journal = {SIGPLAN Not.},
month = jun,
pages = {31–40},
numpages = {10},
keywords = {code generation, compiler, instruction selection, pbqp}
}

@inbook{schafer2007,
author = {Schäfer, Stefan and Scholz, Bernhard},
title = {Optimal chain rule placement for instruction selection based on SSA graphs},
year = {2007},
isbn = {9781450378345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1269843.1269857},
doi = {10.1145/1269843.1269857},
abstract = {Instruction selection is a compiler optimisation that translates the intermediate representation of a program into a lower intermediate representation or an assembler program. We use the SSA form as an intermediate representation for instruction selection. Patterns are used for translation and are expressed as production rules in a graph grammar. The instruction selector seeks for a syntax derivation with minimal costs optimising execution time, code size, or a combination of both. Production rules are either base rules which match nodes in the SSA graph or chain rules which convert results of operations.We present a new algorithm for placing chain rules in a control flow graph. This new algorithm places chain rules optimally for an arbitrary cost metric. Experiments with the MiBench and SPEC2000 benchmark suites show that our proposed algorithm is feasible and always yields better results than simple strategies currently in use. We reduce the costs for placing chain rules by 25\% for the MiBench suite and by 11\% for the SPEC2000 suite.},
booktitle = {Proceedingsof the 10th International Workshop on Software \& Compilers for Embedded Systems},
pages = {91–100},
numpages = {10},
location = {Nice, France},
series = {SCOPES '07}
}

@article{cooper2001,
author = {Cooper, Keith D. and Simpson, L. Taylor and Vick, Christopher A.},
title = {Operator strength reduction},
year = {2001},
issue_date = {September 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {5},
issn = {0164-0925},
url = {https://doi.org/10.1145/504709.504710},
doi = {10.1145/504709.504710},
abstract = {Operator strength reduction is a technique that improves compiler-generated code by reformulating certain costly computations in terms of less expensive ones. A common case arises in array addressing expressions used in loops. The compiler can replace the sequence of multiplies generated by a direct translation of the address expression with an equivalent sequence of additions. When combined with linear function test replacement, strength reduction can speed up the execution of loops containing array references. The improvement comes from two sources: a reduction in the number of operations needed to implement the loop and the use of less costly operations.This paper presents a new algorithm for operator strength reduction, called OSR. OSR improves upon an earlier algorithm of Allen, Cocke, and Kennedy [Allen et al. 1981]. OSR operates on the static single assignment (SSA) form of a procedure [Cytron et al. 1991]. By taking advantage of the properties of SSA form, we have derived an algorithm that is simple to understand, quick to implement, and, in practice, fast to run. Its asymptotic complexity is, in the worst case, the same as the Allen, Cocke,and Kennedy algorithm (ACK). OSR achieves optimization results that are equivalent to those obtained with the ACK algorithm. OSR has been implemented in several research and production compilers.},
journal = {ACM Trans. Program. Lang. Syst.},
month = sep,
pages = {603–625},
numpages = {23},
keywords = {strength reduction, static single assignment form, loops}
}

@article{briggs1992,
author = {Briggs, Preston and Cooper, Keith D. and Torczon, Linda},
title = {Rematerialization},
year = {1992},
issue_date = {July 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {7},
issn = {0362-1340},
url = {https://doi.org/10.1145/143103.143143},
doi = {10.1145/143103.143143},
abstract = {This paper examines a problem that arises during global register allocation – rematerialization. If a value cannot be kept in a register, the allocator should recognize when it is cheaper to recompute the value (rematerialize it) than to store and reload it. Chaitin's original graph-coloring allocator handled simple instance of this problem correctly. This paper details a general solution to the problem and presents experimental evidence that shows its importance.Our approach is to tag individual values in the procedure's SSA graph with information specifying how it should be spilled. We use a variant of Wegman and Zadeck's sparse simple constant algorithm to propagate tags throughout the graph. The allocator then splits live ranges into values with different tags. This isolates those values that can be easily rematerialized from values that require general spilling. We modify the base allocator to use this information when estimating spill costs and introducing spill code.Our presentation focuses on rematerialization in the context of Chaitin's allocator; however, the problem arises in any global allocator. We believe that our approach will work in other allocators–while the details of implementation will vary, the key insights should carry over directly.},
journal = {SIGPLAN Not.},
month = jul,
pages = {311–321},
numpages = {11}
}

@article{hassan2015,
   title={An Implementation Model for Interaction Nets},
   volume={183},
   ISSN={2075-2180},
   url={https://cgi.cse.unsw.edu.au/~eptcs/content.cgi?TERMGRAPH2014},
   urldate={25-8-8},
   journal={Electronic Proceedings in Theoretical Computer Science},
   publisher={Open Publishing Association},
   author={Hassan, Abubakar and Mackie, Ian and Sato, Shinya},
   year={2015},
   month=may, pages={66–80},
   note={https://cgi.cse.unsw.edu.au/~eptcs/content.cgi?TERMGRAPH2014. Accessed: 2025-08-08. A PDF version can be found at: https://doi.org/10.4204/eptcs.183.5}
 }

@article{lafont1997,
title = {Interaction Combinators},
journal = {Information and Computation},
volume = {137},
number = {1},
pages = {69-101},
year = {1997},
issn = {0890-5401},
doi = {https://doi.org/10.1006/inco.1997.2643},
url = {https://www.sciencedirect.com/science/article/pii/S0890540197926432},
author = {Yves Lafont},
abstract = {It is shown that a very simple system ofinteraction combinators, with only three symbols and six rules, is a universal model of distributed computation, in a sense that will be made precise. This paper is the continuation of the author's work oninteraction nets, inspired by Girard's proof nets forlinear logic, but no preliminary knowledge of these topics is required for its reading.}
}

@inbook{girard1995, 
  place={Cambridge}, 
  series={London Mathematical Society Lecture Note Series}, 
  title={Proof nets}, 
  booktitle={Advances in Linear Logic}, 
  publisher={Cambridge University Press}, 
  year={1995}, 
  collection={London Mathematical Society Lecture Note Series},
  author={
Jean-Yves Girard and Yves Lafont and Laurent Regnier},
  isbn={978-1316702291}
}

@inbook{johnsson1985,
author="Johnsson, Thomas",
editor="Jouannaud, Jean-Pierre",
title="Lambda lifting: Transforming programs to recursive equations",
booktitle="Functional Programming Languages and Computer Architecture",
year="1985",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="190--203",
abstract="Lambda lifting is a technique for transforming a functional program with local function definitions, possibly with free variables in the function definitions, into a program consisting only of global function (combinator) definitions which will be used as rewrite rules. Different ways of doing lambda lifting are presented, as well as reasons for rejecting or selecting the method used in our Lazy ML compiler. A functional program implementing the chosen algorithm is given.",
isbn="978-3-540-39677-2",
doi="10.1007/3-540-15975-4_37"
}

@article{sussman1998,
  title     = {Scheme: An Interpreter for Extended Lambda Calculus},
  author    = {Sussman, Gerald Jay and Steele, Guy L.},
  journal   = {Higher-Order and Symbolic Computation},
  volume    = {11},
  number    = {4},
  pages     = {405--439},
  year      = {1998},
  publisher = {Springer},
  doi       = {10.1023/A:1010035624696}
}

@webpage{might2011,
  author       = {Matthew Might},
  title        = {Continuation Passing Style (CPS) Conversion},
  url = {https://matt.might.net/articles/cps-conversion/},
  urldate = {2025-07-16},
  year         = {2011}
}

@article{10.1145/202530.202532,
author = {Kelsey, Richard A.},
title = {A correspondence between continuation passing style and static single assignment form},
year = {1995},
issue_date = {March 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3},
issn = {0362-1340},
url = {https://doi.org/10.1145/202530.202532},
doi = {10.1145/202530.202532},
abstract = {We define syntactic transformations that convert continuation passing style (CPS) programs into static single assignment form (SSA) and vice versa. Some CPS programs cannot be converted to SSA, but these are not produced by the usual CPS transformation. The CPS→SSA transformation is especially helpful for compiling functional programs. Many optimizations that normally require flow analysis can be performed directly on functional CPS programs by viewing them as SSA programs. We also present a simple program transformation that merges CPS procedures together and by doing so greatly increases the scope of the SSA flow information. This transformation is useful for analyzing loops expressed as recursive procedures.},
journal = {SIGPLAN Not.},
month = mar,
pages = {13–22},
numpages = {10}
}

@inbook{kelsey1995,
author = {Kelsey, Richard A.},
title = {A correspondence between continuation passing style and static single assignment form},
year = {1995},
isbn = {0897917545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/202529.202532},
doi = {10.1145/202529.202532},
abstract = {We define syntactic transformations that convert continuation passing style (CPS) programs into static single assignment form (SSA) and vice versa. Some CPS programs cannot be converted to SSA, but these are not produced by the usual CPS transformation. The CPS→SSA transformation is especially helpful for compiling functional programs. Many optimizations that normally require flow analysis can be performed directly on functional CPS programs by viewing them as SSA programs. We also present a simple program transformation that merges CPS procedures together and by doing so greatly increases the scope of the SSA flow information. This transformation is useful for analyzing loops expressed as recursive procedures.},
booktitle = {Papers from the 1995 ACM SIGPLAN Workshop on Intermediate Representations},
pages = {13–22},
numpages = {10},
location = {San Francisco, California, USA},
series = {IR '95}
}

@inbook{dahl2025, 
  place={Las Vegas, Nevada}, 
  title={Mizu: A Lightweight Multi-Threaded Threaded-Code Interpreter that Can Run Almost Anywhere with a C++ Compiler},
  booktitle={The 23rd IEEE/ACIS International Conference on Software Engineering, Management and Applications}, 
  author={Dahl, Joshua and Contaldi, Quinn and Partovi, Kianna and Harris Jr., Frederick C.},
} 