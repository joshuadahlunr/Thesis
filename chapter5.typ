#import "util.typ": unumbered_heading 

= A Methodology For Qualitatively Verifying Compiler Features <chapter:verification>

// This chapter is the basis for a publication which is in the process of being submitted as a publication.

#unumbered_heading(centered: true)[Abstract]

There is a notable gap in the academic literature regarding whether users prefer certain features in modern programming language design. 
Thus, we conducted a user study with twelve C programmers, asking them to complete tasks in both standard C and a version enhanced with Uniform Function Call Syntax (UFCS). 
While objective metrics like completion time and error rates showed no statistically significant differences, 75% of participants preferred the UFCS version. 
However, our small sample size limits the strength of these conclusions.

== Introduction

This paper introduces a compact preprocessor~@dahlufcs we developed—just a single function in size—that extends the C programming language with Uniform Function Calling Syntax (UFCS)~@ufcs: adding method calls to C without adding anything else from Object Oriented programming. 
The tool processes C code enhanced with UFCS and outputs standard C code. 
The primary goal of this extension is to improve developer experience, particularly in mathematical and computational contexts, by enabling the chaining of functions in a more intuitive and readable manner.

This tool is specifically targeted at software developers, with a focus on those working in embedded systems where C’s low-level control is essential. 
The single-function processor is wrapped in a command-line application that accepts an input file and an output file; alternatively, either file can be replaced with “.” to indicate standard input or output, making the tool suitable for use in Unix-style piping workflows.
The output generated by this application is fully compatible with standard C compilers, such as GCC, ensuring seamless integration into existing development toolchains.

There exist several similar preprocessors that extend or transform the C programming language, with the most well-known example being C++, which began its life as a C preprocessor. 
Originally called CFront~@cfront, C++ started as a tool that translated extended C syntax into standard C code, though it has evolved significantly over the past three decades into a fully-fledged language of its own.

Continuing in the tradition of CFront, Herb Sutter—chair of the C++ standards committee—is currently developing an experimental project called CPPFront~@cppfront. 
This tool processes a new syntax known as "CPP2" and translates it into standard C++. 
Unlike the modest scope of UFCS C, CPPFront is an ambitious initiative that incorporates a wide range of modern C++ features while aiming to improve their syntax and usability.

In contrast, UFCS C focuses narrowly on one specific idea (UFCS), which we regard as one of the most impactful features introduced by CPPFront. 
Rather than overhauling the language, UFCS C applies this single enhancement to C, aiming to evaluate its benefits in isolation.

This paper sets out to compare UFCS C with standard C, focusing on both quantitative and qualitative aspects of developer experience. 
We hypothesize that development time and error rates will remain roughly equivalent (within an acceptable margin of error), but that UFCS C will offer a more pleasant and intuitive experience for developers.

The next section provides a review of related work, examining similar studies in language design and usability. 
Following that, @5:sect:method outlines the methodology and structure of our experiment, while @5:sect:results presents the findings derived from our study.
In @5:sect:future, we discuss the limitations of our current approach and explore potential directions for future improvements. 
Finally, @5:sect:conclusion offers a summary of our conclusions based on the experiment and analysis.

== Background <5:sect:background>

Other languages, such as Nim~@nim, also support compiling to C as a backend. 
However, UFCS C distinguishes itself by its minimalism, concentrating solely on the integration of UFCS into C and assessing its potential to improve developer experience within the bounds of traditional C workflows.

Qualitative research on programming language syntax and design is relatively rare in the academic literature; few studies have scientifically examined how humans perceive and interact with different syntactic constructs. However, a notable exception is the work of Stefik and Sieberth~@stefik2013, which was motivated by challenges they had previously encountered while designing programming languages for blind users~@stefik2011.

In their study, Stefik and Sieberth conducted a comprehensive comparison of various programming languages, evaluating their syntax from the perspectives of both programmers and non-programmers. 
The study also investigated preferences for individual syntax elements and keywords in isolation. 
Their findings revealed that many commonly used keywords—such as `for` and `while`—are actually unintuitive not only to non-programmers but also to experienced programmers.
// In the better paper we should be sure to cite quorum

Buse, Sadowski, and Weimer~@buse2011 put a figure on just how rare language user studies are: finding that fewer than 5% of papers categorized under "programming language" or "language constructs and features" include an associated user study. 
In their broader survey on the challenges facing qualitative research in computer science, the most frequently cited obstacle was the difficulty of recruiting participants. 
This barrier often prevents researchers from conducting user studies that could validate or challenge assumptions about language design.

As a potential remedy to this issue, Chamberlain~@chamberlain2017 proposed leveraging online platforms for participant recruitment, specifically suggesting Amazon’s Mechanical Turk as a scalable and accessible way to gather study participants for empirical research.

== Methods <5:sect:method>

Inspired by the work of those who came before us, we developed a simple preprocessor that translates C code written with UFCS into standard C.

=== Preprocessor Design

UFCS can be thought of as generalizing the concept of methods (where a function is called on an object) to apply to any free function. 
This allows developers to write expressions where the first argument appears before the function name, separated by a dot, followed by any additional arguments in the usual format. 
An example of this syntax is shown in @lst:ufcs-code.
#figure(
```c
// -b +/- sqrt(b*b - 4ac)/2a
vec2 inside = vec2_multiply(a, c);
vec2 inside = vec2_divide(vec2_sqrt(vec2_subtract(
  vec2_multiply(b, b), vec2_scalar_multiply(inside, 4)
)), vec2_scalar_multiply(a, 2));
vec2 positive = vec2_add(vec2_negate(b), inside);
vec2 negative = vec2_subtract(vec2_negate(b), inside);

// The above C code can be rewritten as the 
//  following UFCS code

// -b +/- sqrt(b*b - 4ac)/2a
vec2 inside = a.vec2_multiply(c).vec2_scalar_multiply(4);
inside = b.vec2_multiply(b).vec2_subtract(inside);
inside = vec2_sqrt(inside).vec2_divide(
  ~> a.vec2_scalar_multiply(2)
);
vec2 positive = vec2_negate(b).vec2_add(inside);
vec2 negative = vec2_negate(b).vec2_subtract(inside);
```,
placement: auto,
caption: [C code (top) and its equivalent UFCS code (bottom). Notice how the UFCS code can be read from left to right just like the equivalent math.]
) <ufcs-code>

The implementation of the preprocessor is intentionally minimal. 
It is a small C++ program that reads in a file and uses a high-throughput regular expression library (CTRE @ctre) to detect UFCS-style "method" calls. 
Once detected, the preprocessor rewrites these expressions into standard function calls by rearranging the captured groups in the following regular expression pattern:

```
((?:[^.;=\n]*?\.)+)([^(!\n]*?)\s*(\([^)]*\)|\[[^\]]*\])
```

This approach allows us to support UFCS with minimal overhead, while maintaining compatibility with standard C compilers.

=== Participants

We recruited twelve participants for our study, the majority of whom were students from the University of Nevada, Reno’s Computer Science and Engineering program. We were given permission to recruit from the computer science capstone course, and thus the majority were seniors just finishing up their degrees. All but one of the participants identified as male, and their programming experience ranged from just six months to over 40 years.

In terms of language background, the participants were predominantly familiar with C++ and Python. Additionally, there was one participant with experience in TypeScript and another in MATLAB, adding a bit of diversity to the overall programming experience within the group.

=== Apparatus

The apparatus used for this experiment was again intentionally simple:
Participants were seated at a relatively secluded desk in our research laboratory (shown in @fig:desk.)

#figure(
  image("figures/Desk.png"),
  placement: top,
  caption: [The desk in our research laboratory that was used for the experiment.]
) <desk>

The workstation at the desk was running Ubuntu 24.04 and was equipped with both GCC~@gcc and Visual Studio Code~@vscode, creating a familiar development environment for most participants. 
A snapshot of the state of the desktop environment following the completion of a task is shown in @fig:environment.

#figure(
  image("figures/Environment.png"),
  scope: "parent",
  placement: bottom,
  caption: [An example of the development environment after a participant finished one of their tasks.]
) <environment>

Participants were also provided with an executable capable of preprocessing UFCS C code into standard C, along with a small C library containing several utility functions for manipulating `Vector2` structures.
Additionally, a Python-based keylogger ran in the background throughout each task, recording keypresses and mouse activity to help quantify participant behavior during the experiment.

=== Experiment Design

This study employed a between-subjects design with two participant groups. 
Participants were divided based on the order in which they completed tasks: even-numbered participants began with the "Sort" task, while odd-numbered participants started with the "File" task.

This task ordering was the only true counterbalancing applied in the study. 
The language order instead followed a fixed sequence: C, UFCS, UFCS, C. 
This ensured that across the full participant pool, each task was completed with both C and UFCS as the starting language, thereby distributing potential ordering effects evenly.

Since UFCS C is a syntactic modification of standard C (a language all participants were already familiar with) we believed that introducing C first would help establish a baseline. 
Any learning effect would then support a more balanced understanding of both language variants, since there was already a learning bias towards C.

For the purposes of analysis, we treated both programming language (C vs. UFCS) and task type (File vs. Sort) as independent variables. 
Our dependent variables were execution time and approximate error rate.

=== Procedure

The study began with participants being provided a consent form, which they were asked to read carefully before signing. 
To make the process more engaging, they were also presented with a humorous summary of the key points, which included: "3-5 tasks depending on how you count, you're free to leave at any time, there is no direct benefit to you, and if you get hurt, we have band-aids available."

Once they had agreed to participate and signed the consent form, participants were given an entry questionnaire. 
This questionnaire gathered some basic demographic information, such as their years of programming experience and their most-used programming language.

The participants were first introduced to the Visual Studio Code~@vscode environment and instructed to write a simple "hello world" program in C. 
They were then guided through the process of compiling this program using GCC. 
Following this, they were shown how to convert the same program into UFCS C, and were taught how the preprocessor works, including how its output could be piped into GCC for compilation.

Next, the participants were introduced to the `Vector2` library. 
They were tasked with creating a variable to hold the vector (1, 2), and then using the library's utilities to print the vector to the console.
The participants were then asked to write a FizzBuzz program in UFCS C. 
This task was designed to test their familiarity with the `for` loop and `if` statement language constructs. 

After completing the introductory tasks, they were offered time to explore the language further before moving on to the next section.
None of the participants requested additional time during the session. 
However, a few later expressed interest in experimenting with the preprocessor once the experiment had concluded.

The key logger was then started, and the participants were given one of two tasks based on whether they had an odd or even participant number. 
Odd-numbered participants received a cheat sheet containing instructions for loading files. 
They were shown a file with ten random `Vector2` structures and asked to read these vectors into an array, then print them out. 
Meanwhile, even-numbered participants were given a cheat sheet with pseudocode for bubble sort and a list of five Vector2 structures. 
Their task was to hardcode these vectors into an array, sort the array using the bubble sort algorithm, and then print the sorted array.

All participants were initially asked to complete the task using C. 
Once they had finished, they were instructed to perform the same task again, but this time using UFCS C, they were allowed to refer to their previous solution but not copy anything. 
Afterward, each participant was asked to complete the task that the other group had tackled first, starting with UFCS C and then repeating the task using C.

Participants were then asked to complete a combined task, where they needed to load vectors from a file and then sort them. 
They were allowed to choose whichever language they preferred to complete this task.
After finishing the task, participants were given an exit survey. 
The survey asked them to indicate which language they had used for the final task and included several Likert scale questions to assess whether they preferred UFCS C.

=== Measurements

Participants were asked to write three small programs, each focusing on a different task. 
The first program involved loading files, the second sorted an array, and the third combined the previous two tasks. 
If the code began to exceed the length of a single screen in Visual Studio Code, participants were explicitly instructed to keep it within a manageable length.

A key logger was running during each task, tracking both the participants' keystrokes and mouse movements. 
To measure the total execution time for each task, we subtracted the timestamp of the first event the key logger recorded from the timestamp of the last event recorded, using the result as the total time for that task.

Additionally, we counted sequential backspace and delete keypresses, treating each series of consecutive presses as a single "mistake." 
This number was then added to the count of how many times the participant hit Control+Z, and the total was used as an approximation for the number of mistakes made during the task.

The exit questionnaire included subjective preference questions, which were measured using a 7-point Likert scale. 
It also gathered more "objective" preference data based on the participant’s choice of language for the final task.

== Results <5:sect:results>

As a reminder, we went into this work with three hypotheses. 
First, that it would take approximately the same amount of time for participants to perform the same task in C as it would take them in UFCS C. 
Second and similarly, participants would make approximately the same number of mistakes when working with C as compared to UFCS. 
And finally, that participants would subjectively prefer using UFCS C over C.  

The error rate and execution time of the participants are presented in @fig:raw-data. 
The raw data reveals two key patterns: participants generally completed the second task faster than the first, and the second language in each task was almost always faster and more accurate than the first, with only one exception. 

#figure(
  image("figures/UFCS_VS_C_Time&Error.svg", width: 100%),
  caption: [The total number of mistakes (left) and total time (right, measured in seconds) that each participant needed to complete assigned tasks.]
) <raw-data>

The above tables average the raw data using two lenses: @tbl:time-language and @tbl:error-language take the lens of language comparing average C time vs UFCS time (F(1, 6) = 0.322, ns) and C error vs UFCS error (F(1, 6) = 3.776, p > .05), while @tbl:time-task and @tbl:error-task take the lens of task comparing File time vs Sorting time (F(1, 6) = 0.005, ns) and File error vs Sorting error (F(1, 6) = 0.001, ns). 
It appears that Group 2 was composed of slightly better programmers (faster execution and fewer mistakes) than Group 1, however just like every other view of this data, this difference is not statistically significant neither in terms of time (F(1, 6) = 0.381, ns) nor error (F(1, 6) = 2.172, p > .05). 
The lack of any statistical significance in terms of the raw objective data seems to provide some evidence (but of course not proof) for our first two hypotheses expecting similar coding time and error rate. 

#figure(
  table(
    columns: 6,
    align: horizon,
    // inset: 0pt,
    // spacing: (1em, 0.5em),
    stroke: .1pt,
    table.header(
      [*Participant*], [*Group*], [*C Time*], [*UFCS Time*], table.cell(colspan: 2, align: center)[*Average*]
    ),

    [1], table.cell(rowspan: 6)[File], [1974], [1973], [1973.5], table.cell(rowspan:6)[1872.33],
    [3], /*skip*/ [4836], [2734], [3785],
    [5], /*skip*/ [1072], [918], [995],
    [7], /*skip*/ [1461], [2703], [2082],
    [9], /*skip*/ [802], [760], [781],
    [11], /*skip*/ [1493], [1742], [1617.5],

    [2], table.cell(rowspan: 6)[Sort], [2052], [2534], [2293], table.cell(rowspan: 6)[1828.62],
    [4], /*skip*/ [1876], [1110], [1493],
    [6], /*skip*/ [2576], [1572], [2074],
    [8], /*skip*/ [1208], [1701], [1454.5],
    [10], /*skip*/ [882], [1110], [996],
    [12], /*skip*/ [1721], [2565], [2143],
    table.cell(colspan: 2, align: center)[*Average*], [1829.42], [1636.75], table.cell(colspan: 2, align: center)[1850.47],
  ),
  caption: [Average time (in seconds) taken for participants to complete tasks split by C and UFCS C.]
) <time-language>

#figure(
  table(
    columns: 6,
    align: horizon,
    stroke: 0.1pt,
    table.header(
      [*Participant*], [*Group*], [*C Error*], [*UFCS Error*], table.cell(colspan: 2, align: center)[*Average*]
    ),

    [1], table.cell(rowspan: 6)[File], [119], [102], [110.5], table.cell(rowspan: 6)[106.83],
    [3], /*skip*/ [162], [150], [156],
    [5], /*skip*/ [100], [133], [116.5],
    [7], /*skip*/ [64], [123], [93.5],
    [9], /*skip*/ [86], [79], [82.5],
    [11], /*skip*/ [70], [94], [82],

    [2], table.cell(rowspan: 6)[Sort], [107], [130], [118.5], table.cell(rowspan: 6)[84.83],
    [4], /*skip*/ [53], [68], [60.5],
    [6], /*skip*/ [60], [70], [65],
    [8], /*skip*/ [93], [133], [113],
    [10], /*skip*/ [54], [64], [59],
    [12], /*skip*/ [71], [115], [93],
    table.cell(colspan: 2, align: center)[*Average*], [86.58], [105.08], table.cell(colspan: 2, align: center)[95.83],
  ),
  caption: [Average number of mistakes participants made while completing tasks split by C and UFCS C.]
) <error-language>

#figure(
  table(
    columns: 6,
    align: horizon,
    stroke: 0.1pt,
    table.header(
      [*Participant*], [*Group*], [*File Time*], [*Sort Time*], table.cell(colspan: 2, align: center)[*Average*]
    ),

    [1], table.cell(rowspan: 6)[File], [2150], [1797], [1973.5], table.cell(rowspan: 6)[1864.91],
    [3], /*skip*/ [4901], [2669], [3785],
    [5], /*skip*/ [958], [1032], [995],
    [7], /*skip*/ [2540], [1624], [2082],
    [9], /*skip*/ [696], [777], [736.5],
    [11], /*skip*/ [2540], [1624], [2082],

    [2], table.cell(rowspan: 6)[Sort], [2102], [2484], [2293], table.cell(rowspan: 6)[1742.25],
    [4], /*skip*/ [836], [2150], [1493],
    [6], /*skip*/ [1299], [2849], [2074],
    [8], /*skip*/ [1454], [1455], [1454.5],
    [10], /*skip*/ [919], [1073], [996],
    [12], /*skip*/ [2668], [1618], [2143],
    table.cell(colspan: 2, align: center)[*Average*], [1854.33], [1752.83], table.cell(colspan: 2, align: center)[1803.58],
  ),
  caption: [Average time (in seconds) taken for participants to complete tasks split by File and Sorting.]
) <time-task>

#figure(
  table(
    columns: 6,
    align: horizon,
    stroke: 0.1pt,
    table.header(
      [*Participant*], [*Group*], [*File Error*], [*Sort Error*], table.cell(colspan: 2, align: center)[*Average*]
    ),

    [1], table.cell(rowspan: 6)[File], [136], [85], [110.5], table.cell(rowspan: 6)[106.83],
    [3], /*skip*/ [159], [153], [156],
    [5], /*skip*/ [94], [139], [116.5],
    [7], /*skip*/ [97], [90], [93.5],
    [9], /*skip*/ [71], [94], [82.5],
    [11], /*skip*/ [75], [89], [82],

    [2], table.cell(rowspan: 6)[Sort], [108], [129], [118.5], table.cell(rowspan: 6)[84.83],
    [4], /*skip*/ [57], [64], [60.5],
    [6], /*skip*/ [64], [66], [65],
    [8], /*skip*/ [117], [109], [113],
    [10], /*skip*/ [48], [70], [59],
    [12], /*skip*/ [123], [63], [93],

    table.cell(colspan: 2, align: center)[*Average*], [100.17], [91.50], table.cell(colspan: 2, align: center)[95.83],
  ),
  caption: [Average number of mistakes participants made while completing tasks split by File and Sorting.]
) <error-task>

Subjectively, 75% of the participants choose to use UFCS C for their final task. 
Additionally, @fig:likert-responses shows their Likert scale responses all averaged out UFCS was given a 4.44, considering that 4 is indifferent on a 7-point Likert scale which indicates a slight positive sentiment. 

#figure(
  image("figures/StackedRadarChart.svg", width: 100%),
  caption: [The stacked column chart on the left displays the Likert scores for all 12 participants, with color-coded values for each score category. The radar chart on the right illustrates three elements: the upper bound around the mean (orange), the mean itself (blue), and the lower bound around the mean (green), all based on the Likert scores from the 12 participants.]
) <likert-responses>

A one-way ANOVA comparing UFCS performance between C-based and non-C-based language users found no significant difference (F(1,10) = 1.105, p > .05), so we cannot conclude that one group outperformed the other. 
However, trends in performance and familiarity suggest qualitative differences, indicating that language background may affect how easily participants adapt to different syntactic paradigms—warranting further study.

Participants familiar with C-based languages performed better with traditional C (avg. time: 1376.4s) than UFCS (1689.2s), likely due to their comfort with procedural syntax.
In contrast, those unfamiliar with C-based languages performed better with UFCS (1853.7s) compared to traditional C (2153s), a 300-second improvement. 
This may stem from UFCS's method-chaining style, which aligns more with higher-level languages like Python and JavaScript. 
These results suggest UFCS may be a more accessible entry point for newcomers and a valuable teaching tool.

Analyzing the textual reasoning for the subjective responses showed a preference for UFCS-C due to its more object-oriented syntax, especially its similarity to Python’s method-call style (like, var.len).
Many found it more intuitive and clearer for code organization, despite minor issues in conditionals. While some appreciated its novelty and aesthetics, many cited greater comfort with standard C for easier navigation and debugging.
Despite this preference for traditional C in some cases, the dot operator functionality and the resulting code flow were seen positively, allowing for a more focused approach to problem-solving by treating the main variable as the subject of function calls. 

Additionally, the only metric without a slight positive sentiment was productivity; indicating that participants accurately could tell that their execution time between languages was approximately the same. 
Similarly to the objective measures the data seems to support our hypothesis that UFCS C is preferable to standard C, however, the preference is slight. 

== Limitations & Future Work <5:sect:future>

Looking ahead, one of the key limitations of the current preprocessor is that it relies on regular expressions, which makes it poorly suited to handling nested "method" calls. 
As shown in @lst:ufcs-code, the UFCS syntax requires the introduction of a new `~>` operator to clearly indicate where nested methods begin. 
Addressing this ambiguity should be the top priority for anyone continuing development on this project.

Regarding the user study, the sample size of twelve participants is sufficient for establishing baseline acceptability. 
However, to draw stronger, statistically robust conclusions from the data, future studies should aim for a sample size closer to 200 participants, as suggested by a power analysis. 
Given that studies of this nature are often hindered by the difficulty of recruiting enough participants, there is a clear need for a standardized methodology for conducting large-scale programming language user studies. 
Ideally, such a methodology would support online participation while incorporating mechanisms to filter out trolls and otherwise ensure the integrity and validity of the collected data.

== Conclusion <5:sect:conclusion>

In this paper, we introduce an extension to the C programming language that adds support for Uniform Function Call Syntax (UFCS). To evaluate the impact of this extension, we conducted both a qualitative and quantitative user study. Our findings indicate that participants showed a slight preference for UFCS and that its inclusion did not significantly affect their performance. Our work highlights the value of empirically-driven language design, a practice still underutilized in programming language research. Currently, there is a noticeable lack of research in the literature that explores developers’ opinions on programming language features through quantitive studies. Moving forward, we aim to address this gap by contributing further user-study based research in this area. Bridging the gap between theoretical design and user experience could lead to more effective and widely adopted programming languages.

#unumbered_heading[Acknowledgments]
This material is based in part upon work supported by the National Science Foundation under grant number 
OIA-2148788. // T1 Fire
Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.
